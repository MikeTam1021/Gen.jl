{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Gen\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seed so the notebook results are reproducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srand(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Probabilistic programs in Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by learning to use Gen to write generative probabilistic models.\n",
    "In Gen, probabilistic models are represented as *probabilistic programs*. \n",
    "The random choices used inside a probabilistic program represent the random variables in the generative probabilistic model.\n",
    "An assignment of values for some or all of the random choices in a program is called a *trace* of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a probabilistic program\n",
    "Let's begin by writing a typical Bayesian network model as a Gen probabilistic program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilistic program in Gen is a Julia function, in which random choices have been tagged with names using the `~` syntax. The syntax for defining a probabilistic program is slightly different than the standad Julia function definition syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sprinkler_model (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@program sprinkler_model() begin\n",
    "     cloudy = flip(0.5) ~ \"cloudy\"\n",
    "     sprinkler = flip(cloudy ? 0.1 : 0.5) ~ \"sprinkler\"\n",
    "     rain = flip(cloudy ? 0.8 : 0.2) ~ \"rain\"\n",
    "     wetgrass = flip(\n",
    "         if sprinkler\n",
    "             rain ? 0.99 : 0.9\n",
    "         else\n",
    "             rain ? 0.9 : 0.01\n",
    "         end) ~ \"wetgrass\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is:\n",
    "\n",
    "```\n",
    "@program <program-name>(arguments..) begin\n",
    "    <body>\n",
    "end\n",
    "```\n",
    "\n",
    "The arguments are same as standard arguments to a Julia `function`, and can have type declarations as usual. The `<body>` is the same as the body of a standard Julia `function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a probabilistic program\n",
    "\n",
    "Running a probabilistic program is just like running a regular Julia function, except that Gen records the value of each named random choice that was made during the program's execution, into a *probabilistic execution trace*.  The probabilistic program represents a probabilistic generative model, where the random choices are random variables. \n",
    "\n",
    "We run a probabilistic program using the `@generate` macro. The first argument to `@generate` is the trace object in which the choices will be recorded, and the second argument is the function call:\n",
    "\n",
    "```\n",
    "@generate(<trace>, <program-name>(program arguments ...))\n",
    "```\n",
    "\n",
    "An empty trace is constructed with `Trace()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sprinkler_trace = Trace()\n",
    "@generate(sprinkler_trace, sprinkler_model());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the values that were generated, using `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of cloudy is true\n"
     ]
    }
   ],
   "source": [
    "cloudy = value(sprinkler_trace, \"cloudy\")\n",
    "sprinkler = value(sprinkler_trace, \"sprinkler\")\n",
    "rain = value(sprinkler_trace, \"rain\")\n",
    "wetgrass = value(sprinkler_trace, \"wetgrass\")\n",
    "println(\"The value of cloudy is $cloudy\") # NOTE Julia's string interpolation syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "List all possible traces for the `sprinker_model` program above, and the probability for each trace. Check that they sum to 1.0. Feel free to generate\n",
    "the list programatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum of probs: 1.0\n",
      "\n",
      "CSRW\n",
      "----\n",
      "TTTT: 0.0396\n",
      "TTTF: 0.0004\n",
      "TTFT: 0.009\n",
      "TTFF: 0.001\n",
      "TFTT: 0.324\n",
      "TFTF: 0.036\n",
      "TFFT: 0.0009\n",
      "TFFF: 0.0891\n",
      "FTTT: 0.0495\n",
      "FTTF: 0.0005\n",
      "FTFT: 0.18\n",
      "FTFF: 0.02\n",
      "FFTT: 0.045\n",
      "FFTF: 0.005\n",
      "FFFT: 0.002\n",
      "FFFF: 0.198\n"
     ]
    }
   ],
   "source": [
    "# ANSWER HERE\n",
    "\n",
    "#C - cloud T/F\n",
    "#S - sprinkler T/F\n",
    "#R - rain T/F\n",
    "#W - wetgrass T/F\n",
    "\n",
    "probs = [.0396, .0004, .009, .001, .324, .036, .0009, .0891,\n",
    ".0495, .0005, .18, .02, .045, .005, .002, .198]\n",
    "\n",
    "println(\"\\nsum of probs: \", sum(probs), \"\\n\")\n",
    "println(\"CSRW\")\n",
    "println(\"----\")\n",
    "iter = 1\n",
    "for i in [\"T\",\"F\"], j in [\"T\",\"F\"], k in [\"T\",\"F\"], l in [\"T\",\"F\"]\n",
    "    println(string(i, j, k, l), \": \", probs[iter])\n",
    "    iter+=1\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "Give a directed acyclic graph (DAG) expressing the conditional independencies between random choices in the above `sprinkler_model` program (i.e. the Bayesian network for the probabilistic model). Specify the DAG by its vertices and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid operator \"--\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid operator \"--\"",
      ""
     ]
    }
   ],
   "source": [
    "# ANSWER HERE\n",
    "                    \n",
    "            cloudy --> sprinker ------> wetgrass <--\n",
    "                   \\                               /\n",
    "                    \\--> rain --------------------/\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A program with an infinite number of random choices\n",
    "\n",
    "We just saw that probabilistic programs can represent generative models like Bayesian networks. However, probabilistic programs can also represent generative models that cannot be represented as Bayesian networks, including models with an infinite number of possible random choices. Below, `recursion_program` is a simple program with an infinite number of random choices:\n",
    "\n",
    "**Note:** Probabilistic programs are regular Julia functions, and can can be parameterized by adding function parameters. Here, we parameterize the recursion_program by the probability of each flip resulting in heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return values: Any[2,0,1,0,2,5,1,0,1,0,1,1,3,1,3,1,0,2,0,0]\n"
     ]
    }
   ],
   "source": [
    "@program recursion_program(prob_heads::Float64) begin\n",
    "    @generate(foo(0, prob_heads))\n",
    "end\n",
    "\n",
    "@program foo(n::Int, prob_heads::Float64) begin\n",
    "    if (flip(prob_heads) ~ \"flip_$n\")\n",
    "        @generate(foo(n + 1, prob_heads))\n",
    "    else\n",
    "        n\n",
    "    end\n",
    "end\n",
    "\n",
    "return_values = []\n",
    "for i=1:20\n",
    "    push!(return_values, @generate(Trace(), recursion_program(0.5)))\n",
    "end\n",
    "println(\"return values: $return_values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the program above we used Julia's string interpolation syntax to form the random choice names. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip_10\n",
      "flip_20\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "println(\"flip_$n\")\n",
    "println(\"flip_$(n * 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These strings are evaluated during program execution in the same environment as the rest of the code in the probabilistic program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that probabilistic programs can use sub-routines. In the example above, each recursive call to `foo()` records its random choice in the same trace object. A probabilistic program is called as a sub-routine using the `@generate` macro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show that two different executions of the same probabilistic program can result in a different number of random choices made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First execution\n",
      "The value of flip_0 is true\n",
      "The value of flip_1 is false\n",
      "return-value=1\n",
      "\n",
      "Second execution\n",
      "The value of flip_0 is true\n",
      "The value of flip_1 is true\n",
      "The value of flip_2 is false\n",
      "return-value=2\n"
     ]
    }
   ],
   "source": [
    "# One traced execution of recursion_program\n",
    "println(\"\\nFirst execution\")\n",
    "trace = Trace()\n",
    "return_value = @generate(trace ,recursion_program(0.5))\n",
    "for choice in choices(trace)\n",
    "    println(\"The value of $choice is $(value(trace, choice))\")\n",
    "end\n",
    "println(\"return-value=$return_value\")\n",
    "\n",
    "# Another traced execution\n",
    "println(\"\\nSecond execution\")\n",
    "recursion_trace = Trace() \n",
    "return_value = @generate(trace ,recursion_program(0.5))\n",
    "for choice in choices(trace)\n",
    "    println(\"The value of $choice is $(value(trace, choice))\")\n",
    "end\n",
    "println(\"return-value=$return_value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of random choices that were sampled is different between the two executions. Unlike Bayesian networks, probabilistic programs can represent models in which (1) the set of which random choices are sampled is itself a random object, and (2) the set of random choices is potentially countably infinite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next perform 20 independent traced executions of the program. Note that because probabilistic programs are represented as Julia functions, they return values just like normal Julia functions. Below we run the program 20 times and list the return value in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAEpCAYAAAD/D3oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X90VPWd//HXQH4SMpMNwkxSEgiWX4uCEmuIRUWMBsoqOURLODmCFcuuJ3AMgUU4FZRduqHoCs0eIZ4eSGrbSKUWXKTCIkK6SogaxILVnMBGgieZsLWbGQhmiOTz/cPDfDuQ5DIhIRl4Ps655zD3vu9n3h8+xryYmTvXZowxAgAA6ES/3m4AAAD0fQQGAABgicAAAAAsERgAAIAlAgMAALBEYAAAAJYIDAAAwBKBAQAAWCIwAAAASwQGAABgicAAAAAshfV2A13R1tam+vp6xcbGymaz9XY7AACEDGOMzpw5o8TERPXrd+WvG4RkYKivr1dSUlJvtwEAQMg6deqUhg4desX1IRkYYmNjJX07Wbvd3svdAAAQOrxer5KSkvy/S69USAaGi29D2O12AgMAAF0Q7Fv6fOgRAABYIjAAAABLBAYAAGCJwAAAACwFFRief/552Wy2gG3MmDH+48YYrVq1SgkJCYqOjlZGRoZqamoCxmhpaVFeXp4GDRqkgQMHKjs7W42Njd0zGwAA0COCfoVh3Lhxamho8G/vvfee/9i6detUVFSk4uJiVVZWKiYmRpmZmWppafHXLF68WDt37tS2bdtUXl6u+vp6zZo1q3tmAwAAekTQl1WGhYXJ5XJdtt8Yow0bNujZZ5/VzJkzJUmvvvqqnE6nduzYoZycHHk8Hm3evFllZWWaOnWqJKmkpERjx47VoUOHNGnSpHaf0+fzyefz+R97vd5g2wYAAFch6FcYampqlJiYqBEjRig3N1d1dXWSpNraWrndbmVkZPhrHQ6H0tLSVFFRIUmqqqpSa2trQM2YMWOUnJzsr2lPYWGhHA6Hf+NbHgEAuLaCeoUhLS1NpaWlGj16tBoaGrR69WrdfffdOnbsmNxutyTJ6XQGnON0Ov3H3G63IiIiFBcX12FNe1asWKGCggL/44vfUtXdhi/f1e1j9pQv1s7o7RYAADeQoALD9OnT/X8eP3680tLSNGzYML3++usaO3Zstzd3UWRkpCIjI3tsfAAA0LmruqwyLi5Oo0aN0vHjx/2fa7j0iofGxkb/MZfLpfPnz6upqanDGgAA0PdcVWA4e/asjh8/roSEBKWkpMjlcmnfvn3+416vV5WVlUpPT5ckpaamKjw8PKCmurpadXV1/hoAAND3BPWWxNKlS/XQQw9p2LBhqq+v13PPPaewsDDNmTNHNptN+fn5WrNmjUaOHKmUlBStXLlSiYmJysrKkvTthyDnz5+vgoICxcfHy263a9GiRUpPT+/wCgkAAND7ggoMX375pebMmaOvvvpKgwcP1uTJk3Xo0CENHjxYkrRs2TI1NzdrwYIFampq0uTJk7V7925FRUX5x1i/fr369eun7Oxs+Xw+ZWZmauPGjd07KwAA0K1sxhjT200Ey+v1yuFwyOPxdOvtrblKAgBwvevq71DuJQEAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACxdVWBYu3atbDab8vPz/fuMMVq1apUSEhIUHR2tjIwM1dTUBJzX0tKivLw8DRo0SAMHDlR2drYaGxuvphUAANCDuhwYPvzwQ73yyisaP358wP5169apqKhIxcXFqqysVExMjDIzM9XS0uKvWbx4sXbu3Klt27apvLxc9fX1mjVrVtdnAQAAelSXAsPZs2eVm5urX/ziF/q7v/s7/35jjDZs2KBnn31WM2fO1Pjx4/Xqq6+qvr5eO3bskCR5PB5t3rxZL730kqZOnarU1FSVlJTo4MGDOnToULvP5/P55PV6AzYAAHDtdCkw5OXlacaMGcrIyAjYX1tbK7fbHbDf4XAoLS1NFRUVkqSqqiq1trYG1IwZM0bJycn+mksVFhbK4XD4t6SkpK60DQAAuijowLB161YdPnxYhYWFlx1zu92SJKfTGbDf6XT6j7ndbkVERCguLq7DmkutWLFCHo/Hv506dSrYtgEAwFUIC6b41KlTevrpp7V3715FRUX1VE+XiYyMVGRk5DV7PgAAECioVxiqqqp0+vRpTZw4UWFhYQoLC1N5ebmKiooUFhbmf2Xh0iseGhsb5XK5JEkul0vnz59XU1NThzUAAKBvCSow3H///Tp69KiOHDni3+644w7l5ubqyJEjGjFihFwul/bt2+c/x+v1qrKyUunp6ZKk1NRUhYeHB9RUV1errq7OXwMAAPqWoN6SiI2N1S233BKwLyYmRoMGDfLvz8/P15o1azRy5EilpKRo5cqVSkxMVFZWlqRvPwQ5f/58FRQUKD4+Xna7XYsWLVJ6eromTZrUTdMCAADdKajAcCWWLVum5uZmLViwQE1NTZo8ebJ2794d8JmH9evXq1+/fsrOzpbP51NmZqY2btzY3a0AAIBuYjPGmN5uIlher1cOh0Mej0d2u73bxh2+fFe3jdXTvlg7o7dbAACEoK7+DuVeEgAAwBKBAQAAWCIwAAAASwQGAABgicAAAAAsERgAAIAlAgMAALBEYAAAAJYIDAAAwBKBAQAAWCIwAAAASwQGAABgicAAAAAsERgAAIAlAgMAALBEYAAAAJYIDAAAwBKBAQAAWCIwAAAASwQGAABgicAAAAAsERgAAIAlAgMAALBEYAAAAJYIDAAAwBKBAQAAWCIwAAAASwQGAABgicAAAAAsERgAAIAlAgMAALBEYAAAAJYIDAAAwFJQgWHTpk0aP3687Ha77Ha70tPT9fbbb/uPG2O0atUqJSQkKDo6WhkZGaqpqQkYo6WlRXl5eRo0aJAGDhyo7OxsNTY2ds9sAABAjwgqMAwdOlRr165VVVWVPvroI02dOlUzZ87Up59+Kklat26dioqKVFxcrMrKSsXExCgzM1MtLS3+MRYvXqydO3dq27ZtKi8vV319vWbNmtW9swIAAN3KZowxVzNAfHy8XnjhBT3xxBNKTEzUkiVLtHTpUkmSx+OR0+lUaWmpcnJy5PF4NHjwYJWVlemRRx6RJH3++ecaO3asKioqNGnSpHafw+fzyefz+R97vV4lJSXJ4/HIbrdfTfsBhi/f1W1j9bQv1s7o7RYAACHI6/XK4XAE/Tu0y59huHDhgrZu3arm5malp6ertrZWbrdbGRkZ/hqHw6G0tDRVVFRIkqqqqtTa2hpQM2bMGCUnJ/tr2lNYWCiHw+HfkpKSuto2AADogqADw9GjRzVw4EBFRkbqn/7pn7R9+3b9/d//vdxutyTJ6XQG1DudTv8xt9utiIgIxcXFdVjTnhUrVsjj8fi3U6dOBds2AAC4CmHBnjB69GgdOXJEHo9Hv/vd7zRv3jyVl5f3RG9+kZGRioyM7NHnAAAAHQv6FYaIiAh997vfVWpqqgoLCzVhwgT9/Oc/l8vlkqTLrnhobGz0H3O5XDp//ryampo6rAEAAH3PVX8PQ1tbm3w+n1JSUuRyubRv3z7/Ma/Xq8rKSqWnp0uSUlNTFR4eHlBTXV2turo6fw0AAOh7gnpLYsWKFZo+fbqSk5N15swZlZWV6cCBA9qzZ49sNpvy8/O1Zs0ajRw5UikpKVq5cqUSExOVlZUl6dsPQc6fP18FBQWKj4+X3W7XokWLlJ6e3uEVEgAAoPcFFRhOnz6tuXPnqqGhQQ6HQ+PHj9eePXv0wAMPSJKWLVum5uZmLViwQE1NTZo8ebJ2796tqKgo/xjr169Xv379lJ2dLZ/Pp8zMTG3cuLF7ZwUAALrVVX8PQ2/o6jWkVvgeBgDA9e6afw8DAAC4cRAYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFgK+l4S6BtC5RJQLv8EgOsDrzAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGApqMBQWFio733ve4qNjdWQIUOUlZWl6urqgBpjjFatWqWEhARFR0crIyNDNTU1ATUtLS3Ky8vToEGDNHDgQGVnZ6uxsfHqZwMAAHpEUIGhvLxceXl5OnTokPbu3avW1lY9+OCDam5u9tesW7dORUVFKi4uVmVlpWJiYpSZmamWlhZ/zeLFi7Vz505t27ZN5eXlqq+v16xZs7pvVgAAoFvZjDGmqyf/7//+r4YMGaLy8nLdc889MsYoMTFRS5Ys0dKlSyVJHo9HTqdTpaWlysnJkcfj0eDBg1VWVqZHHnlEkvT5559r7Nixqqio0KRJkyyf1+v1yuFwyOPxyG63d7X9ywxfvqvbxsK3vlg7o7dbAAD8ja7+Dr2qzzB4PB5JUnx8vCSptrZWbrdbGRkZ/hqHw6G0tDRVVFRIkqqqqtTa2hpQM2bMGCUnJ/trLuXz+eT1egM2AABw7XQ5MLS1tSk/P1/f//73dcstt0iS3G63JMnpdAbUOp1O/zG3262IiAjFxcV1WHOpwsJCORwO/5aUlNTVtgEAQBd0OTDk5eXp2LFj2rp1a3f2064VK1bI4/H4t1OnTvX4cwIAgP+vS4Fh4cKFeuutt7R//34NHTrUv9/lcknSZVc8NDY2+o+5XC6dP39eTU1NHdZcKjIyUna7PWADAADXTlCBwRijhQsXavv27Xr33XeVkpIScDwlJUUul0v79u3z7/N6vaqsrFR6erokKTU1VeHh4QE11dXVqqur89cAAIC+JSyY4ry8PJWVlenNN99UbGys/zMHDodD0dHRstlsys/P15o1azRy5EilpKRo5cqVSkxMVFZWlr92/vz5KigoUHx8vOx2uxYtWqT09PQrukICAABce0EFhk2bNkmSpkyZErC/pKREjz/+uCRp2bJlam5u1oIFC9TU1KTJkydr9+7dioqK8tevX79e/fr1U3Z2tnw+nzIzM7Vx48armwkAAOgxV/U9DL2F72EIHXwPAwD0Lb3yPQwAAODGQGAAAACWCAwAAMASgQEAAFgiMAAAAEsEBgAAYInAAAAALBEYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFgiMAAAAEsEBgAAYInAAAAALBEYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFgiMAAAAEsEBgAAYInAAAAALBEYAACAJQIDAACwFNbbDeD6Nnz5rt5u4Yp8sXZGb7cAAH0arzAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAUtCB4Y9//KMeeughJSYmymazaceOHQHHjTFatWqVEhISFB0drYyMDNXU1ATUtLS0KC8vT4MGDdLAgQOVnZ2txsbGq5sJAADoMUEHhubmZk2YMEEvv/xyu8fXrVunoqIiFRcXq7KyUjExMcrMzFRLS4u/ZvHixdq5c6e2bdum8vJy1dfXa9asWV2fBQAA6FFBf9Pj9OnTNX369HaPGWO0YcMGPfvss5o5c6Yk6dVXX5XT6dSOHTuUk5Mjj8ejzZs3q6ysTFOnTpUklZSUaOzYsTp06JAmTZp0FdMBAAA9oVs/w1BbWyu3262MjAz/PofDobS0NFVUVEiSqqqq1NraGlAzZswYJScn+2su5fP55PV6AzYAAHDtdGtgcLvdkiSn0xmw3+l0+o+53W5FREQoLi6uw5pLFRYWyuFw+LekpKTubBsAAFgIiaskVqxYIY/H499OnTrV2y0BAHBD6dbA4HK5JOmyKx4aGxv9x1wul86fP6+mpqYOay4VGRkpu90esAEAgGunWwNDSkqKXC6X9u3b59/n9XpVWVmp9PR0SVJqaqrCw8MDaqqrq1VXV+evAQAAfUvQV0mcPXtWx48f9z+ura3VkSNHFB8fr+TkZOXn52vNmjUaOXKkUlJStHLlSiUmJiorK0vStx+CnD9/vgoKChQfHy+73a5FixYpPT2dKyQAAOijgg4MH330ke677z7/44KCAknSvHnzVFpaqmXLlqm5uVkLFixQU1OTJk+erN27dysqKsp/zvr169WvXz9lZ2fL5/MpMzNTGzdu7IbpAACAnmAzxpjebiJYXq9XDodDHo+nWz/PMHz5rm4bC6Hli7UzersFALgmuvo7NCSukgAAAL2LwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCUCAwAAsERgAAAAlggMAADAUlhvNwD0BaF0a3NuxQ2gN/AKAwAAsERgAAAAlggMAADAEoEBAABYIjAAAABLBAYAAGCJwAAAACwRGAAAgCW+uAkIMaHyJVN8wRRwfeEVBgAAYInAAAAALBEYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFjiexgA9Ai+LwK4vvAKAwAAsNSrgeHll1/W8OHDFRUVpbS0NH3wwQe92Q4AAOhAr70l8dvf/lYFBQUqLi5WWlqaNmzYoMzMTFVXV2vIkCG91RaAGwxvnQBXptcCw0svvaQf//jH+tGPfiRJKi4u1q5du7RlyxYtX768t9oCAFwlQtj1qVcCw/nz51VVVaUVK1b49/Xr108ZGRmqqKi4rN7n88nn8/kfezweSZLX6+3Wvtp857p1PADoLsmLt/V2C9edUPk7PbY6s1vHu/i70xgT1Hm9Ehj+8pe/6MKFC3I6nQH7nU6nPv/888vqCwsLtXr16sv2JyUl9ViPAAD0BY4NPTPumTNn5HA4rrg+JC6rXLFihQoKCvyP29ra9Ne//lWDBg2SzWbrlufwer1KSkrSqVOnZLfbu2XMvoT5ha7reW4S8wtl1/PcpOt3fsYYnTlzRomJiUGd1yuB4aabblL//v3V2NgYsL+xsVEul+uy+sjISEVGRgbsi4uL65He7Hb7dfUfxqWYX+i6nucmMb9Qdj3PTbo+5xfMKwsX9cpllREREUpNTdW+ffv8+9ra2rRv3z6lp6f3RksAAKATvfaWREFBgebNm6c77rhDd955pzZs2KDm5mb/VRMAAKDv6P/8888/3xtPfMsttyguLk4//elP9eKLL0qSfvOb32j06NG90Y4kqX///poyZYrCwkLiox1BY36h63qem8T8Qtn1PDfp+p9fMGwm2OsqAADADYd7SQAAAEsEBgAAYInAAAAALBEYAACApRsqMAR7O+0DBw5o4sSJioyM1He/+12VlpZem0aDVFhYqO9973uKjY3VkCFDlJWVperq6k7POXDggGw222Wb2+2+Rl1fueeff/6yPseMGdPpOaGydsOHD293HfLy8tqt7+vr9sc//lEPPfSQEhMTZbPZtGPHjoDjxhitWrVKCQkJio6OVkZGhmpqaizH3bZtm8aMGaOoqCjdeuut+sMf/tBTU+hUZ/NrbW3VM888o1tvvVUxMTFKTEzU3LlzVV9f3+mYpaWll61nVFRUT0/lMlZr9/jjj1/W57Rp0yzHDYW1k9Tuz5XNZtMLL7zQ4Zh9Ze2ulRsmMFy8nfZzzz2nw4cPa8KECcrMzNTp06fbra+trdWMGTN033336ciRI8rPz9eTTz6pPXv2XOPOrZWXlysvL0+HDh3S3r171draqgcffFDNzc2W51ZXV6uhocG/9dVbi48bNy6gz/fee6/D2lBauw8//DBgXnv37pUkPfroo52e11fXrbm5WRMmTNDLL7/c7vF169apqKhIxcXFqqysVExMjDIzM9XS0tLhmAcPHtScOXM0f/58ffzxx8rKylJWVpaOHTvWU9PoUGfzO3funA4fPqyVK1fq8OHD+v3vf6/q6mo9/PDDluPa7faA9Tx58mRPtN8pq7WTpGnTpgX0+dprr3U6ZqisnaSAeTU0NGjLli2y2WzKzs7udNy+sHbXjLlB3HnnnSYvL8//+MKFCyYxMdEUFha2W79s2TIzbty4gH2zZ882mZmZPdpndzh9+rSRZMrLyzus2b9/v5Fk/u///u8adtY1zz33nJkwYcIV14fy2j399NPm5ptvNm1tbe0eD6V1k2S2b9/uf9zW1mZcLpd54YUX/PuamppMZGSkee211zoc54c//KGZMWNGwL60tDTzj//4j93fdBAunV97PvjgAyPJnDx5ssOakpIS43A4uru9q9Le3ObNm2dmzpwZ1DihvHYzZ840U6dO7bSmL65dT7ohXmG4eDvtjIwM/77ObqctSRUVFQH1kpSZmdlhfV9y8fbf8fHxlrW33XabEhIS9MADD+j999/v6da6rKamRomJiRoxYoRyc3NVV1fXYW2ort358+f161//Wk888YTlTdVCZd3+Vm1trdxud8DaOBwOpaWldbo2obqe0rc/izabzfLeN2fPntWwYcOUlJSkmTNn6tNPP71GHQbnwIEDGjJkiEaPHq2nnnpKX331Vaf1obp2jY2N2rVrl+bPn29ZGypr1x1uiMDQ2e20O3rv1+12t1vv9Xr19ddf91ivV6utrU35+fn6/ve/r1tuuaXDuoSEBBUXF+uNN97QG2+8oaSkJE2ZMkWHDx++ht1embS0NJWWlmr37t3atGmTamtrdffdd+vMmTPt1ofq2u3YsUNNTU16/PHHO6wJpXW71MWftWB+Di+eF+w5fUFLS4ueeeYZzZkzp9MbF40ePVpbtmzRm2++qV//+tdqa2vTXXfdpS+//PIadmtt2rRpevXVV7Vv3z797Gc/U3l5uaZPn64LFy50eE6ort0vf/lLxcbGatasWZ3WhcradRe+6/I6k5eXp2PHjnX6Hr/07X/of/s13HfddZdOnDih9evX61e/+lVPtxmU6dOn+/88fvx4paWladiwYXr99dev6F8AoWLz5s2aPn16p7ecDaV1u5G1trbqhz/8oYwx2rRpU6e16enpATfdu+uuuzR27Fi98sor+td//deebvWK5eTk+P986623avz48br55pt14MAB3X///b3YWffbsmWLcnNzLT/AGCpr111uiFcYgr2dtiS5XK526+12u6Kjo3us16uxcOFCvfXWW9q/f7+GDh0a9Pl33nmnjh8/3gOdda+4uDiNGjWqw15Dce1Onjypd955R08++WTQ54bKul38WQvm5/DiecGe05suhoWTJ09q7969Qd8WOTw8XLfffnufX9MRI0bopptu6rTPUFs7Sfrv//5vVVdXd+lnMVTWrqtuiMDQldtpp6enB9RL0t69e/vk7beNMVq4cKG2b9+ud999VykpKV0a58iRI0pISOjm7rrf2bNndfz48Q57DaW1u6ikpERDhgzRjBkzgj43VNYtJSVFLpcrYG28Xq8qKys7XZtQWs+LYaGmpkbvvPOOBg0aFPQYFy5c0NGjR/v8mn755Zf66quvOu0zlNbuos2bNys1NVUTJkwI+txQWbsu6+1PXV4rW7duNZGRkaa0tNT8+c9/NgsWLDBxcXHG7XYbY4xZvny5eeyxx/z1//M//2MGDBhg/vmf/9l89tln5uWXXzb9+/c3u3fv7q0pdOipp54yDofDHDhwwDQ0NPi3c+fO+Wsund/69evNjh07TE1NjTl69Kh5+umnTb9+/cw777zTG1Po1JIlS8yBAwdMbW2tef/9901GRoa56aabzOnTp40xob12xnx7xU5ycrJ55plnLjsWaut25swZ8/HHH5uPP/7YSDIvvfSS+fjjj/1XCaxdu9bExcWZN9980/zpT38yM2fONCkpKebrr7/2j/HYY4+Z5cuX+x+///77JiwszLz44ovms88+M88995wJDw83R48e7VPzO3/+vHn44YfN0KFDzZEjRwJ+Fn0+X4fzW716tdmzZ485ceKEqaqqMjk5OSYqKsp8+umnfWZuZ86cMUuXLjUVFRWmtrbWvPPOO2bixIlm5MiRpqWlpcO5hcraXeTxeMyAAQPMpk2b2h2jr67dtXLDBAZjjPmP//gPk5ycbCIiIsydd95pDh065D82b948c++99wbU79+/39x2220mIiLCjBgxwpSUlFzbhq+QpHa3v+330vn97Gc/MzfffLOJiooy8fHxZsqUKebdd9+99s1fgdmzZ5uEhAQTERFhvvOd75jZs2eb48eP+4+H8toZY8yePXuMJFNdXX3ZsVBbt4uXfV66zZs3zxjz7aWVK1euNE6n00RGRpr777//snnfe++9/vqLXn/9dTNq1CgTERFhxo0bZ3bt2nWNZhSos/nV1tZ2+LO4f/9+/xiXzi8/P9///yWn02l+8IMfmMOHD/epuZ07d848+OCDZvDgwSY8PNwMGzbM/PjHP/b/g+uiUF27i1555RUTHR1tmpqa2h2jr67dtcLtrQEAgKUb4jMMAADg6hAYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFgiMAAAAEsEBgAAYInAACCkPP/887rtttt6uw3ghkNgAG4Q/KIFcDUIDECIO3/+/DV9PmOMvvnmm2v6nAB6H4EBCDFTpkzRwoULlZ+fr5tuukmZmZmSpKamJj355JMaPHiw7Ha7pk6dqk8++USSVFpaqtWrV+uTTz6RzWaTzWZTaWmpvvjiC9lsNh05csQ/flNTk2w2mw4cOCBJOnDggGw2m95++22lpqYqMjJS7733nv8Vi1/96lcaPny4HA6HcnJydObMmXb79nq9io6O1ttvvx2wf/v27YqNjdW5c+ckSc8884xGjRqlAQMGaMSIEVq5cqVaW1s7/fvIz88P2JeVlaXHH3/c/9jn82np0qX6zne+o5iYGKWlpfnnB+DKEBiAEPTLX/5SERERev/991X46x8wAAAEqElEQVRcXCxJevTRR3X69Gm9/fbbqqqq0sSJE3X//ffrr3/9q2bPnq0lS5Zo3LhxamhoUENDg2bPnh3Ucy5fvlxr167VZ599pvHjx0uSTpw4oR07duitt97SW2+9pfLycq1du7bd8+12u/7hH/5BZWVlAft/85vfKCsrSwMGDJAkxcbGqrS0VH/+85/185//XL/4xS+0fv36YP+KAixcuFAVFRXaunWr/vSnP+nRRx/VtGnTVFNTc1XjAjeSsN5uAEDwRo4cqXXr1vkfv/fee/rggw90+vRpRUZGSpJefPFF7dixQ7/73e+0YMECDRw4UGFhYXK5XF16zn/5l3/RAw88ELCvra1NpaWlio2NlSQ99thj2rdvn37605+2O0Zubq4ee+wxnTt3TgMGDJDX69WuXbu0fft2f82zzz7r//Pw4cO1dOlSbd26VcuWLetS33V1dSopKVFdXZ0SExMlSUuXLtXu3btVUlKif/u3f+vSuMCNhsAAhKDU1NSAx5988onOnj2rQYMGBez/+uuvdeLEiW55zjvuuOOyfcOHD/eHBUlKSEjQ6dOnOxzjBz/4gcLDw/Wf//mfysnJ0RtvvCG73a6MjAx/zW9/+1sVFRXpxIkTOnv2rL755hvZ7fYu93306FFduHBBo0aNCtjv8/ku+/sC0DECAxCCYmJiAh6fPXtWCQkJ7b4vHxcX1+E4/fp9+66kMca/r6PPC1z6nJIUHh4e8Nhms6mtra3D54uIiNAjjzyisrIy5eTkqKysTLNnz1ZY2Lf/K6qoqFBubq5Wr16tzMxMORwObd26Vf/+7//e6Rz+tv9L53D27Fn1799fVVVV6t+/f0DdwIEDOxwXQCACA3AdmDhxotxut8LCwjR8+PB2ayIiInThwoWAfYMHD5YkNTQ06Pbbb5ekgA9A9oTc3Fw98MAD+vTTT/Xuu+9qzZo1/mMHDx7UsGHD9JOf/MS/7+TJk52ON3jwYDU0NPgfX7hwQceOHdN9990nSbr99tt14cIFnT59WnfffXc3zwa4cfChR+A6kJGRofT0dGVlZem//uu/9MUXX+jgwYP6yU9+oo8++kjSt28f1NbW6siRI/rLX/4in8+n6OhoTZo0yf9hxvLy8oDPEPSEe+65Ry6XS7m5uUpJSVFaWpr/2MiRI1VXV6etW7fqxIkTKioqCvh8Q3umTp2qXbt2adeuXfr888/11FNPqampyX981KhRys3N1dy5c/X73/9etbW1+uCDD1RYWKhdu3b12DyB6w2BAbgO2Gw2/eEPf9A999yjH/3oRxo1apRycnJ08uRJOZ1OSVJ2dramTZum++67T4MHD9Zrr70mSdqyZYu++eYbpaamKj8/P+Bf/D3V65w5c/TJJ58oNzc34NjDDz+sxYsXa+HChbrtttt08OBBrVy5stPxnnjiCc2bN09z587VvffeqxEjRvhfXbiopKREc+fO1ZIlSzR69GhlZWXpww8/VHJycrfPD7he2cylb/4BAABcglcYAACAJQIDAACwRGAAAACWCAwAAMASgQEAAFgiMAAAAEsEBgAAYInAAAAALBEYAACAJQIDAACwRGAAAACW/h/Kg1LrHY2uEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f07aba47250>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "return_values = []\n",
    "for i=1:1000\n",
    "    push!(return_values, recursion_program(Trace(), 0.7))\n",
    "end\n",
    "plt[:figure](figsize=(6, 3))\n",
    "plt[:hist](return_values)\n",
    "plt[:xlabel](\"return value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the program again 20 times with a different parameter. Note that because probabilistic programs are represented as Julia functions, they can take arbitrary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f07ab5e2d90>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "return_values = []\n",
    "for i=1:1000\n",
    "    push!(return_values, recursion_program(Trace(), 0.4))\n",
    "end\n",
    "plt[:figure](figsize=(6, 3))\n",
    "plt[:hist](return_values)\n",
    "plt[:xlabel](\"return value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, changing that parameter has a pretty drastic effect on the distribution of return values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.3\n",
    "\n",
    "Recall that a trace is the set of random choices and their values.\n",
    "\n",
    "(a) List the set of possible traces for the recursion_example program above, the probability of each possible trace, and the value of output for each trace. Do the probabilities sum to 1?\n",
    "\n",
    "(b) Describe the marginal distribution of output.\n",
    "\n",
    "(c) Can you draw a Bayesian network corresponding to `recursion_program`?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # ANSWER HERE\n",
    "(a) Trace |  Returns |  Prob\n",
    "_______________________________\n",
    "    flip_0=0   0        0.9\n",
    "-------------------------------\n",
    "    flip_0=1   \n",
    "    flip_1=0   1        0.1 * 0.9\n",
    "-------------------------------\n",
    "    flip_0=1\n",
    "    flip_1=1   \n",
    "    flip_2=0   2        (0.1)^2 * 0.9\n",
    "-------------------------------\n",
    "    flip_0=1\n",
    "    flip_1=1\n",
    "    flip_2=1\n",
    "    flip_3=0   3        (0.1)^3 * 0.9\n",
    "-------------------------------\n",
    "    flip_0=1\n",
    "    flip_1=1\n",
    "    flip_2=1\n",
    "    flip_3=1\n",
    "    flip_4=0   4        (0.1)^4 * 0.9\n",
    "-------------------------------\n",
    "        ...etc...\n",
    "\n",
    "Yes. It adds up to 1. \n",
    "\n",
    "(b) As the _return value increases the probability of that \n",
    "    value returning exponentially decreases. The rate it which\n",
    "    it becomes more unlikely to reach higher _return values\n",
    "    depends on the prob_heads variable\n",
    "\n",
    "    Geometric Distribution\n",
    "\n",
    "(c) Not Really\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraining a trace\n",
    "\n",
    "Recall the probablistic programs `sprinkler_model` and `recursion_program`. As seen above, the trace holds random variables and their respective values which were randomly generated by the program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring a Trace\n",
    "\n",
    "Instead of finding the probabilities of a particular Trace of a probablistic program by hand, we can use `trace.log_weight` to automatically find the log probability of that trace. If we sum the `exp(trace.log_weight)` i.e. the exponential of the log probability (to cancel out the log) of each unique Trace, should equal to 1.\n",
    "\n",
    "#### Example of logs and the exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-probability of 0.47 is -0.7550225842780328\n",
      "The exponential of -0.7550225842780328 is 0.47\n"
     ]
    }
   ],
   "source": [
    "#Turning a probability into a log-probability\n",
    "example_prob = .47\n",
    "example_log_prob = log(example_prob)\n",
    "println(\"Log-probability of $example_prob is $example_log_prob\")\n",
    "\n",
    "\n",
    "#Going backwards: Turning a log-probability back into a probability\n",
    "example_exp_log_prob = exp(example_log_prob)\n",
    "println(\"The exponential of $example_log_prob is $example_exp_log_prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Listed below** are the probabilites of two unique traces for the `sprinkler_model`\n",
    "in the following format: **`[trace]:[trace_probability]`**\n",
    "\n",
    "** Note these probabilities are not log probabilities yet\n",
    "\n",
    "1. **cloudy=T, sprinkler=T, rain=T, wetgrass=T : 0.0396**\n",
    "\n",
    "2. **cloudy=T, sprinkler=T, rain=T, wetgrass=F : 0.0004**\n",
    "\n",
    "Let's test if `trace.log_weight` returns the same values we computed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. cloudy=T, sprinkler=T, rain=T, wetgrass=T : 0.0396 \n",
    "trace = Trace()\n",
    "constrain!(trace, \"cloudy\", true)\n",
    "constrain!(trace, \"sprinkler\", true)\n",
    "constrain!(trace, \"rain\", true)\n",
    "constrain!(trace, \"wetgrass\", true)\n",
    "\n",
    "# Run the model\n",
    "@generate(trace, sprinkler_model())\n",
    "\n",
    "# Check that the score matches our calculation\n",
    "@assert isapprox(score(trace), log(0.0396))\n",
    "\n",
    "# 2. cloudy=T, sprinkler=T, rain=T, wetgrass=F :  0.0004 \n",
    "trace = Trace()\n",
    "constrain!(trace, \"cloudy\", true)\n",
    "constrain!(trace, \"sprinkler\", true)\n",
    "constrain!(trace, \"rain\", true)\n",
    "constrain!(trace, \"wetgrass\", false)\n",
    "\n",
    "# Run the model\n",
    "@generate(trace, sprinkler_model())\n",
    "\n",
    "# Check that the score matches our calculation\n",
    "@assert isapprox(score(trace), log(0.0004))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, let's test the probabilites of another 2 traces for the `recursion_program`:\n",
    "\n",
    "1. **flip_0 = 0  : 0.9**\n",
    "\n",
    "2. **flip_0 = 1, flip_1 = 0 : 0.1 * 0.9 **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. flip_0 = 0 : 0.9\n",
    "trace = Trace()\n",
    "constrain!(trace, \"flip_0\", false)\n",
    "\n",
    "# Run the model\n",
    "@generate(trace, recursion_program(0.1))\n",
    "\n",
    "# Check that the score matches calculation\n",
    "@assert isapprox(score(trace), log(0.9))\n",
    "\n",
    "# 2. flip_0 = 1, flip_1 = 0 : 0.01\n",
    "trace = Trace()\n",
    "constrain!(trace, \"flip_0\", true)\n",
    "constrain!(trace, \"flip_1\", false)\n",
    "\n",
    "# Run the model\n",
    "@generate(trace, recursion_program(0.1))\n",
    "\n",
    "# Check that the score matches calculation\n",
    "@assert isapprox(score(trace), log(0.1 * 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if you contrain some (not all) of the random variables? \n",
    "\n",
    "In the `sprinkler_model`, let's constrain:\n",
    "* cloud = True\n",
    "* sprinkler = False\n",
    "\n",
    "Let's then say the probablistic program fills the rest of the random variables in the trace as:\n",
    "* rain = False\n",
    "* wetgrass = True\n",
    "\n",
    "**Question 1 (True or False):** Is the score the same as if all of the random values were contrained to: \n",
    "\n",
    "* cloud = True\n",
    "* sprinkler = False\n",
    "* rain = False\n",
    "* wetgrass = True \n",
    "\n",
    "?\n",
    "\n",
    "#### Answer: False\n",
    "\n",
    "### Why is this False? Let's explain the math by an example of Importance Sampling.\n",
    "\n",
    "According to the Chain rule `P(X=x|Y=y) = P(X=x, Y=y) / P(Y=y)`\n",
    "\n",
    "`P(X=x|Y=y)` represents some true distribution that we desire to find and describe. We can do this by trying to estimate it as closely as possible with another distribution. Let's call this estimation distribution `q(X=x)`. In the graph below, we draw an example of what `P(X=x|Y=y)` (green) might look like and what the initial estimate `q(X=x)` (orange) may be.\n",
    "<img src=\"distrib_ex.png\"  style=\"width: 300px; float: center\"/>\n",
    "\n",
    "Let A, B, C, and D represent drawn samples from `q(X=x)`. In importance sampling, we wish to score the sample, or particle that most matches `P(X=x|Y=y)`. We do this by giving each particle (A, B, C, and D) a score, or weight. The higher the score, or the more it weighs, the more it matches `P(X=x|Y=y)`. This score is computed as `weight_i = P(X=x_i|Y=y) / q(X=x_i)` Below, we illustrate the weights of each particle, A, B, C, and D with blue circles. The larger the circle is drawn, the more weight it has. This means that particle B is a more accurate sample of what `P(X=x|Y=y)` actually represents.\n",
    "\n",
    "<img src=\"distrib_2_ex.png\"  style=\"width: 300px; float: center\"/>\n",
    "\n",
    "This weight is synonmous to the log probabilities we were computing earlier. This means that we can find the weight of a particular trace using `trace.log_weight`. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"b_net_ex.png\"  style=\"width: 250px; float: left\"/>\n",
    "\n",
    "On the left we show an example of a bayes net of the `sprinkler_model`. Where `cloudy` and `sprinkler` are contrained, and `rain` and `wetgrass` are not.\n",
    "\n",
    "If we wanted to find the score, or weight of this particular trace (which represents a particle, or sample of a probablistic program) we would compute the weights as: \n",
    "\n",
    "` P(cloudy) * P(sprinkler|cloudy) * P(rain|cloudy) * P(wetgrass| sprinkler, rain) / P(rain|cloudy) * P(wetgrass| sprinkler, rain)`\n",
    "\n",
    "Since there are no custom proposals, the program defaults to the prior. The non-contrained probabilities, `P(rain|cloudy)` and `P(wetgrass| sprinkler, rain)`, cancel out, and we are left with:\n",
    "\n",
    "\n",
    "` P(cloudy) * P(sprinkler|cloudy)` \n",
    "\n",
    "which is not equal to \n",
    "\n",
    "`P(cloudy) * P(sprinkler|cloudy) * P(rain|cloudy) * P(wetgrass| sprinkler, rain)` \n",
    "\n",
    "If `cloudy=True and sprinkler=False`, we get `0.5 * 0.9` = 0.45.\n",
    "The log probability is `log(0.45) = 798507696217771`. Therefore, this weight is different from the weight of a trace where all the random variables are contrained. \n",
    "\n",
    "**Below we run `sprinkler_model` with the contraints of `cloudy=True and sprinkler=False`.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching setindex!(::Gen.Trace, ::Bool, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching setindex!(::Gen.Trace, ::Bool, ::String)",
      ""
     ]
    }
   ],
   "source": [
    "# Set constraints\n",
    "sprinkler_trace = Trace()\n",
    "sprinkler_trace[\"cloudy\"] = true\n",
    "sprinkler_trace[\"sprinkler\"] = false\n",
    "\n",
    "# Run the model\n",
    "sprinkler_model(sprinkler_trace)\n",
    "\n",
    "# Print the trace\n",
    "println(\"cloudy=\", sprinkler_trace[\"cloudy\"]) \n",
    "println(\"sprinkler=\", sprinkler_trace[\"sprinkler\"])\n",
    "println(\"rain=$rain\", sprinkler_trace[\"rain\"]) # This value is assigned by the model\n",
    "println(\"wetgrass=\", sprinkler_trace[\"wetgrass\"]) # This value is assigned by the model\n",
    "println(\"-------------------\")\n",
    "\n",
    "# Show the score of the trace\n",
    "println(\"Our Answer:\", log(0.5 * 0.9))\n",
    "println(\"sprinkler_trace.log_weight=\",sprinkler_trace.log_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the probabilistic program `shared_or_separate` below. Note that we have parameterized this program by a `num_obs` parameter. Also note that we do not name all of the random choices. In Gen, not all random choices need to be named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition shared_or_separate(Gen.Trace, Int64) in module Main at In[18]:2 overwritten at In[52]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shared_or_separate (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function shared_or_separate(T::Trace, num_obs::Int)\n",
    "    mean_shared = normal(0., 10.)\n",
    "    mean_1 = normal(0., 10.)\n",
    "    mean_2 = normal(0., 10.)\n",
    "    variance = Gen.gamma(1., 1.)\n",
    "    shared = flip(0.2) ~ \"shared\"\n",
    "    outputs = []\n",
    "    for i=1:num_obs\n",
    "        if i < num_obs / 2\n",
    "            # cohort 1 (first half of data points)\n",
    "            if shared\n",
    "                mu = mean_shared\n",
    "            else\n",
    "                mu = mean_1\n",
    "            end\n",
    "        else\n",
    "            # cohort 2 (second half of data points)\n",
    "            if shared\n",
    "                mu = mean_shared\n",
    "            else\n",
    "                mu = mean_2\n",
    "            end\n",
    "        end\n",
    "        push!(outputs, normal(mu, sqrt(variance)) ~ \"output-$i\")\n",
    "    end\n",
    "    return outputs\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run this program many times, and plot the histogram of the outputs for each run. We use PyPlot which is a Julia package that wraps Python's matplotlib module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "all_traces = []\n",
    "for replicate=1:24\n",
    "    trace = Trace()\n",
    "    outputs = shared_or_separate(trace, 50)\n",
    "    push!(all_outputs, outputs)\n",
    "    push!(all_traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Gen.Trace, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Gen.Trace, ::String)",
      "",
      " in macro expansion; at ./In[54]:5 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "plt[:figure](figsize=(9, 6))\n",
    "for (i, outputs) in enumerate(all_outputs)\n",
    "    \n",
    "    #Changing color based on behavior of the data\n",
    "    shared = all_traces[i][\"shared\"]\n",
    "    c = \"teal\"\n",
    "    if shared\n",
    "        c = \"orange\"\n",
    "    end\n",
    "    \n",
    "    plt[:subplot](6, 4, i)\n",
    "    plt[:hist](outputs, bins=50, range=(-25, 25), color=(c))\n",
    "    ax = plt[:gca]()\n",
    "    plt[:gca]()[:get_yaxis]()[:set_visible](false)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.4\n",
    "\n",
    "(a) Describe what the `shared_or_separate` program above is doing, and a possible use of this program as a probabilistic model of data.\n",
    "\n",
    "(b) Run a new experiment where you extract the value of `shared` for each run of the program, and and use the value of `shared` to improve the histogram, by coloring the runs for which `shared=true` differently fromthe renderings for which `shared=false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"In\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"In\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "# ANSWER HERE\n",
    "\n",
    "(a) In shared_or_separate, there is a .2 probability that data will be created as a unimodal\n",
    "    distribution, meaning that all of the data/samples will be drawn from a single \n",
    "    normal distrubtion centered at one mean. 80% of the time the program will \n",
    "    be created as a bimodal distribution: half of the data points will be drawn \n",
    "    from one of two normals, and the other half will be drawn \n",
    "    from the latter normal distribution. \n",
    "\n",
    "    The number of data points created is a user determined variable.\n",
    "   \n",
    "    This model can be a simple generative model that describes the test scores \n",
    "    of a particular college class. Most of the time, half of the class scores really well,\n",
    "    and the other half scores badly. Ever so often, the class will be more in sync and\n",
    "    score in a more normal fashion. \n",
    "\n",
    "(b) Done! The graphs colored orange represent unimodal distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilistic program below defines a Bayesian linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear_regression(T::Trace, xs::Array{Float64,1})\n",
    "    slope = normal(0., 2.) ~ \"slope\"\n",
    "    intercept = normal(0., 2.) ~ \"intercept\"\n",
    "    variance = 1.0\n",
    "    line = (x::Float64) -> intercept + slope * x\n",
    "    ys = map(\n",
    "            (i) -> normal(line(xs[i]), variance) ~ \"y$i\", \n",
    "            1:length(xs))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching keys(::Gen.Trace)\u001b[0m\nClosest candidates are:\n  keys(\u001b[1m\u001b[31m::PyCall.PyObject\u001b[0m) at /home/marcoct/.julia/v0.5/PyCall/src/PyCall.jl:293\n  keys(\u001b[1m\u001b[31m::PyPlot.ColorMap\u001b[0m) at /home/marcoct/.julia/v0.5/PyPlot/src/colormaps.jl:27\n  keys(\u001b[1m\u001b[31m::PyPlot.Figure\u001b[0m) at /home/marcoct/.julia/v0.5/PyPlot/src/PyPlot.jl:71\n  ...\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching keys(::Gen.Trace)\u001b[0m\nClosest candidates are:\n  keys(\u001b[1m\u001b[31m::PyCall.PyObject\u001b[0m) at /home/marcoct/.julia/v0.5/PyCall/src/PyCall.jl:293\n  keys(\u001b[1m\u001b[31m::PyPlot.ColorMap\u001b[0m) at /home/marcoct/.julia/v0.5/PyPlot/src/colormaps.jl:27\n  keys(\u001b[1m\u001b[31m::PyPlot.Figure\u001b[0m) at /home/marcoct/.julia/v0.5/PyPlot/src/PyPlot.jl:71\n  ...\u001b[0m",
      "",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "trace = Trace()\n",
    "linear_regression(trace, [-3., -2., -1., 0., 1., 2., 3.])\n",
    "for key in keys(trace)\n",
    "    println(\"$key=$(trace[key])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the traces for many repeated executions. We will visualize the `slope` and `intercept` by plotting the corresponding line, and we will scatterplot the x, y pairs. We visualize a trace by writing a *trace rendering* function, that takes a trace and any other input parameters as arguments and draws a plot onto the current axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "xs = collect(linspace(-5.0, 5.0, 20))\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    linear_regression(trace, xs)\n",
    "    push!(traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render_linear_regression_trace (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function render_linear_regression_trace(trace::Trace,\n",
    "                                         xs::Array{Float64,1},\n",
    "                                         ax, xlim, ylim)\n",
    "    slope = trace[\"slope\"]\n",
    "    intercept = trace[\"intercept\"]\n",
    "    ys = map((i) -> trace[\"y$i\"], 1:length(xs))\n",
    "    ax[:scatter](xs, ys, lw=0, s=50)\n",
    "    ax[:plot](xlim, slope * xlim + intercept, color=\"green\", lw=4)\n",
    "    ax[:set_xlim](xlim)\n",
    "    ax[:set_ylim](ylim)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Gen.Trace, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Gen.Trace, ::String)",
      "",
      " in render_linear_regression_trace(::Gen.Trace, ::Array{Float64,1}, ::PyCall.PyObject, ::Array{Float64,1}, ::Array{Float64,1}) at ./In[25]:4",
      " in macro expansion; at ./In[26]:7 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_trace(trace, xs, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.5\n",
    "\n",
    "Run a number of traced executions of `linear_regression` with modified inputs, render the outputs, and describe how your change affects the prior distribution on traces. For example, what happens if you increase the variance of the prior on the slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Gen.Trace, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Gen.Trace, ::String)",
      "",
      " in render_linear_regression_trace(::Gen.Trace, ::Array{Float64,1}, ::PyCall.PyObject, ::Array{Float64,1}, ::Array{Float64,1}) at ./In[25]:4",
      " in macro expansion; at ./In[27]:29 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "# ANSWER HERE\n",
    "\n",
    "function linear_regression_modified(T::Trace, xs::Array{Float64,1}, \n",
    "        slope_var::Float64, intercept_var::Float64)\n",
    "    slope = normal(0., slope_var) ~ \"slope\"\n",
    "    intercept = normal(0., intercept_var) ~ \"intercept\"\n",
    "    variance = 1.0\n",
    "    line = (x::Float64) -> intercept + slope * x\n",
    "    ys = map(\n",
    "            (i) -> normal(line(xs[i]), variance) ~ \"y$i\", \n",
    "            1:length(xs))\n",
    "end\n",
    "\n",
    "\n",
    "traces = []\n",
    "xs = collect(linspace(-5.0, 5.0, 20))\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    linear_regression_modified(trace, xs, 5., 1.)\n",
    "    push!(traces, trace)\n",
    "end\n",
    "\n",
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_trace(trace, xs, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: line break in \":\" expression",
     "output_type": "error",
     "traceback": [
      "syntax: line break in \":\" expression",
      ""
     ]
    }
   ],
   "source": [
    "Explaination:\n",
    "\n",
    "\n",
    "In the graphs above, I changed the variance of the sampled slopes to 5, \n",
    "and the variance of the sampled y-intercept to 1. \n",
    "\n",
    "Since the variance of the slope increases, there's more of a chance that the slopes will be\n",
    "large values.. which me ans that the lines will tend to be more verticle.\n",
    "\n",
    "The y-intercept's variance makes sure the that y-intercept is more likely to be 0. \n",
    "All the lines will look like they are trying to cross the 0,0 mark on the plots. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program below shows an extended version of the linear regression model, where each data point may be an outlier or an inlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_regression_outliers (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear_regression_outliers(T::Trace, xs::Array{Float64,1})\n",
    "    inlier_noise = gamma(1., 1.) ~ \"inlier_noise\"\n",
    "    outlier_noise = 10.0\n",
    "    prob_outlier = 0.1\n",
    "    slope = normal(0.0, 2.0) ~ \"slope\"\n",
    "    intercept = normal(0.0, 2.0) ~ \"intercept\"\n",
    "    ys = Array{Float64, 1}(length(xs))\n",
    "    for i=1:length(xs)\n",
    "        y_mean = intercept + slope * xs[i]\n",
    "        noise = (flip(prob_outlier) ~ \"o$i\") ? outlier_noise : inlier_noise \n",
    "        ys[i] = normal(y_mean, noise) ~ \"y$i\"\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a new trace rendering for it that shows the outlier data points in red, and shows the value of `inlier_noise` using error bars above and below the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render_linear_regression_outliers_trace (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function render_linear_regression_outliers_trace(trace::Trace,\n",
    "                                                 xs::Array{Float64,1},\n",
    "                                                 ax, xlim, ylim)\n",
    "    slope = trace[\"slope\"]\n",
    "    intercept = trace[\"intercept\"]\n",
    "    ys = map((i) -> trace[\"y$i\"], 1:length(xs))\n",
    "    outlier_statuses = map((i) -> trace[\"o$i\"], 1:length(xs))\n",
    "    inlier_noise = trace[\"inlier_noise\"]\n",
    "    colors = map((i) -> outlier_statuses[i] ? \"red\" : \"blue\", 1:length(xs))\n",
    "    ax[:scatter](xs, ys, lw=0, s=50, c=colors)\n",
    "    line = intercept + slope * xlim\n",
    "    ax[:plot](xlim, slope * xlim + intercept, color=\"green\", lw=4)\n",
    "    plt[:fill_between](xlim, line - inlier_noise, line, color=\"black\", alpha=0.3)\n",
    "    plt[:fill_between](xlim, line, line + inlier_noise, color=\"black\", alpha=0.3)\n",
    "    ax[:set_xlim](xlim)\n",
    "    ax[:set_ylim](ylim)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "xs = collect(linspace(-5.0, 5.0, 20))\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    linear_regression_outliers(trace, xs)\n",
    "    push!(traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Gen.Trace, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Gen.Trace, ::String)",
      "",
      " in render_linear_regression_outliers_trace(::Gen.Trace, ::Array{Float64,1}, ::PyCall.PyObject, ::Array{Float64,1}, ::Array{Float64,1}) at ./In[30]:4",
      " in macro expansion; at ./In[32]:7 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_outliers_trace(trace, xs, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you understand how to write probabilistic models in Gen, and how to understand their behavior by visualizing simulations from the models. Next, we will show how to perform approximate probabilistic inference in Gen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Approximate probabilistic inference\n",
    "Probabilistic inference in a Gen model involves finding values for latent variables that are compatible with a set of *constraints* placed on the trace of the program. A *constraint* is a value for a random choice made within the program. We express constraints in Gen by setting values in the trace that we pass into a probabilistic program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the program below has one latent random choice (`mu`) and three observed random choices (`x1`, `x2`, and `x3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_model (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simple_model(T::Trace)\n",
    "    mu = normal(0.0, 10.0) ~ \"mu\"\n",
    "    x1 = normal(mu, 1.0) ~ \"x1\"\n",
    "    x2 = normal(mu, 1.0) ~ \"x2\"\n",
    "    x3 = normal(mu, 1.0) ~ \"x3\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We wish to infer likely values of `mu` given specific observed values for `x1`, `x2`, and `x3`. First, we create an empty trace, and add constraints to it by setting `x1` through `x3` to their observed values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
      ""
     ]
    }
   ],
   "source": [
    "trace = Trace()\n",
    "trace[\"x1\"] = 3.4\n",
    "trace[\"x2\"] = 4.6\n",
    "trace[\"x3\"] = 4.2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood estimate for `mu` is the mean of the data, and we expect the Bayesian posterior over `mu` should be concentrated near that point, shifted downwards somewhat due to the prior. For this dataset, we expect a reasonable inference algorithm to give values for `mu` lying in the range 3.5-4.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of Gen (and most other probabilistic programming languages) is that, given a trace and a program, it automatically computes a score that indicates how probable the trace is. Let's compute the score for a reasonable value of `mu` and an unreasonable value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
      ""
     ]
    }
   ],
   "source": [
    "trace = Trace()\n",
    "trace[\"x1\"] = 3.4\n",
    "trace[\"x2\"] = 4.6\n",
    "trace[\"x3\"] = 4.2;\n",
    "trace[\"mu\"] = 4.0 # reasonable value\n",
    "simple_model(trace);\n",
    "println(\"score for reasonable mu $(trace.log_weight)\")\n",
    "\n",
    "trace = Trace()\n",
    "trace[\"x1\"] = 3.4\n",
    "trace[\"x2\"] = 4.6\n",
    "trace[\"x3\"] = 4.2;\n",
    "trace[\"mu\"] = -10.0 # unreasonable value\n",
    "simple_model(trace)\n",
    "println(\"score for unreasonable mu $(trace.log_weight)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have the program propose its own values for `mu` from the prior, and return the score for the proposed value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching setindex!(::Gen.Trace, ::Float64, ::String)",
      "",
      " in macro expansion; at ./In[36]:3 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "for i=1:3\n",
    "    trace = Trace()\n",
    "    trace[\"x1\"] = 3.4\n",
    "    trace[\"x2\"] = 4.6\n",
    "    trace[\"x3\"] = 4.2;\n",
    "    simple_model(trace);\n",
    "    mu = trace[\"mu\"] # get value proposed by the program\n",
    "    println(\"score for mu=$mu:  $(trace.log_weight)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple inference algorithms are easy to write in Gen using this scoring functionality. Gen also allows the user to write their own algorithms and programs for probabilistic inference that make use of core Gen abstractions. Here we show how to write a simple likelihood-weighting inference algorithm using Gen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood-weighting involves sampling from the prior `num_samples` times (by running the model program forward), weighting each sample by the likelihood of the observed data, and then picking one of the prior samples at random, proportional to its weight. See the following paper for a description of this class of algorithms, called sampling importance resampling (SIR): https://fisher.osu.edu/~schroeder.9/AMIS900/Smith1992.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to inference in Gen, is the ability to provide *constraints* on a trace. Instead of just getting values back from the program through the trace, we can also set values in the trace before we pass it into the program. These values then serve as *constraints* on the trace. When the Gen program encounters a named random choice during its execution, it will check if a value for that random choices appears in the trace. If it does, it will use that value, and increment a *score* which represents the log-likelihood of the contraints given the sampled trace. If the trace does not contain a value for the random choice, it will simulate the random choice as usual (e.g. from the prior). This basic operation allows us to easily implement likelihood-weighting. The score of the resulting traces (a.k.a. the *log-weight*) is the log likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When the Gen program encounters a named random choice during its execution, it will check if a value for that random choices appears in the trace. If it does, it will use that value, and increment a *score* which represents the log-likelihood of the contraints given the sampled trace. If the trace does not contain a value for the random choice, it will simultae the random choice as usual (e.g. from the prior). This basic operation allows us to easily implement likelihood-weighting. The score of the resulting traces (a.k.a. the *log-weight*) is the log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: @in not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: @in not defined",
      ""
     ]
    }
   ],
   "source": [
    "function logsumexp(x::Array{Float64,1})\n",
    "    maxx = maximum(x)\n",
    "    maxx + log(sum(exp(x - maxx)))\n",
    "end\n",
    "\n",
    "function linear_regression_likelihood_weighting(num_samples::Int, xs::Array{Float64,1}, \n",
    "                                               ys::Array{Float64,1})\n",
    "    log_weights = Array{Float64,1}(num_samples)\n",
    "    traces = Array{Trace,1}(num_samples)\n",
    "    for sample=1:num_samples\n",
    "        trace = Trace()\n",
    "        @in trace begin\n",
    "            for (i, y) in enumerate(ys)\n",
    "                @constrain(\"y$i\", y) # equivalent to trace[\"y$i\"] = y\n",
    "            end\n",
    "        end\n",
    "        linear_regression_outliers(trace, xs)\n",
    "        traces[sample] = trace\n",
    "        log_weights[sample] = trace.log_weight\n",
    "    end\n",
    "    weights = exp(log_weights - logsumexp(log_weights))\n",
    "    chosen = rand(Distributions.Categorical(weights))\n",
    "    return traces[chosen]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set up an example dataset that has one clear outlier, and run our inference algorithm, to check that it correctly infers which datapoints are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f07b30a0d50>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = collect(linspace(-5., 5., 10))\n",
    "ys = xs + randn(10) * 0.2\n",
    "ys[4] = -ys[4]\n",
    "plt[:figure](figsize=(5, 5))\n",
    "plt[:scatter](xs, ys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run likelihood-weighting 36 times, where each run uses 10,000 samples from the prior. This might take a several seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: linear_regression_likelihood_weighting not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: linear_regression_likelihood_weighting not defined",
      "",
      " in macro expansion; at ./In[39]:5 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "traces = []\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    num_samples = 10000\n",
    "    push!(traces, linear_regression_likelihood_weighting(num_samples, xs, ys))\n",
    "end\n",
    "\n",
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_outliers_trace(trace, xs, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the samples should show the outlier in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That inference algorithm was a little slow, because we had to wait for it. Let's see what happens when we use a less accurate but faster version, that only uses 100 samples from the prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: linear_regression_likelihood_weighting not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: linear_regression_likelihood_weighting not defined",
      "",
      " in macro expansion; at ./In[40]:5 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "traces = []\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    num_samples = 100\n",
    "    push!(traces, linear_regression_likelihood_weighting(num_samples, xs, ys))\n",
    "end\n",
    "\n",
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_outliers_trace(trace, xs, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.1\n",
    "\n",
    "The distribution on traces produced by the inference algorithm above seems to be mostly 'unimodal' because most of the probability mass is concentrated within one contiguous region in the set of traces, or centered at one trace.\n",
    "\n",
    "Create a new dataset that results in a bimodal posterior distribution on the slope and intercept. Run the likelihoog-weighting inference algorithm on that dataset and visualize the traces to see the bimodality.\n",
    "\n",
    "NOTE: Do not simply create a bimodal prior. The prior on slope and intercept must be unimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x7f07b2d80d90>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ANSWER HERE\n",
    "\n",
    "# DOWNWARD ARROW --------------\n",
    "# xs_pos = collect(linspace(0., 2.5, 4))\n",
    "# println(\"xs_pos:$xs_pos\")\n",
    "\n",
    "# ys_pos = collect(linspace(0, 2.5, 4))\n",
    "# println(\"ys_pos:$ys_pos\")\n",
    "\n",
    "# xs_neg = collect(linspace(0., -2.5, 4))\n",
    "\n",
    "# ys_neg = collect(linspace(0, 2.5, 4))\n",
    "\n",
    "# println(\"xs_neg:$xs_neg\")\n",
    "# println(\"ys_neg:$ys_neg\")\n",
    "\n",
    "# DOWNWARD ARROW --------------\n",
    "\n",
    "\n",
    "\n",
    "# plt[:figure](figsize=(5, 5))\n",
    "# plt[:scatter](xs_pos, ys_pos);\n",
    "# plt[:scatter](xs_neg, ys_neg);\n",
    "\n",
    "# xs_ = vcat(xs_pos,xs_neg)\n",
    "# ys_ = vcat(ys_pos,ys_neg)\n",
    "\n",
    "# plt[:figure](figsize=(5, 5))\n",
    "# plt[:scatter](xs_, ys_);\n",
    "\n",
    "\n",
    "# 5 points\n",
    "xs_ = [-3.8, 3.6, -3.7, 0, 3.5]\n",
    "ys_ = [3.6, -3.5, -3.6, 0, 3.5]\n",
    "\n",
    "plt[:figure](figsize=(5, 5))\n",
    "plt[:scatter](xs_, ys_);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we see the likelihoods for proposals from the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: @in not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: @in not defined",
      ""
     ]
    }
   ],
   "source": [
    "function linear_regression_raw_likelihood_weighting(num_samples::Int, xs::Array{Float64,1}, \n",
    "                                               ys::Array{Float64,1})\n",
    "    traces = Array{Trace,1}(num_samples)\n",
    "    log_weights = Array{Float64,1}(num_samples)\n",
    "    for sample=1:num_samples\n",
    "        trace = Trace()\n",
    "        @in trace begin\n",
    "            for (i, y) in enumerate(ys)\n",
    "                @constrain(\"y$i\", y) # equivalent to trace[\"y$i\"] = y\n",
    "            end\n",
    "        end\n",
    "        linear_regression_outliers(trace, xs)\n",
    "        traces[sample] = trace\n",
    "        log_weights[sample] = trace.log_weight\n",
    "    end\n",
    "    return traces, log_weights\n",
    "end\n",
    "    \n",
    "\n",
    "traces = []\n",
    "log_weights = []\n",
    "num_samples = 36\n",
    "\n",
    "traces, log_weights = linear_regression_raw_likelihood_weighting(num_samples, xs_, ys_)\n",
    "\n",
    "\n",
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    ax[:title][:set_text](log_weights[i])\n",
    "    #print(\"trace: $trace\")\n",
    "    render_linear_regression_outliers_trace(trace, xs_, ax, xlim, ylim)\n",
    "    \n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Focus on one sample from the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: linear_regression_raw_likelihood_weighting not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: linear_regression_raw_likelihood_weighting not defined",
      ""
     ]
    }
   ],
   "source": [
    "traces = []\n",
    "log_weights = []\n",
    "num_samples = 1\n",
    "\n",
    "traces, log_weights = linear_regression_raw_likelihood_weighting(num_samples, xs_, ys_)\n",
    "\n",
    "plt[:figure](figsize=(1.7, 1.8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](1, 1, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    ax[:title][:set_text](log_weights[i])\n",
    "    render_linear_regression_outliers_trace(trace, xs_, ax, xlim, ylim)\n",
    "    \n",
    "end\n",
    "plt[:tight_layout]()\n",
    "\n",
    "println(\"log_weights/likelihood: $(log_weights[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities by hand\n",
    "\n",
    "\n",
    "\n",
    "To begin finding the weight for this sample by \"hand\", let's \n",
    "\n",
    "**1.write the joint probability of the generative model for `linear_regression_outliers`**\n",
    "\n",
    "**Notation**\n",
    "\n",
    "Let `G` represent Gamma, `N` Normal, `B` Bernoulli, and `PI` as \"`the product of`\" .\n",
    "Also let `prob_in` and `prob_out` represent the proability of a coordinate being an inlier and outlier respectively.\n",
    "\n",
    "`P_G(prob_in; 1,1) * P_N(m; 0,2) * P_N(b; 0,2) * ( i=1 to N PI( P_B(o_i) )) *  ( i=1 to N PI( P_N( y_i; m*x_i+b, o_i(prob_out) + (1-o_i)*prob_in))`\n",
    "\n",
    "**2.write the proposal**\n",
    "\n",
    "`P_G(prob_in; 1,1) * P_N(m; 0,2) * P_N(b; 0,2) * ( i=1 to N PI( P_B(o_i) ))`\n",
    "\n",
    "**3.calculate the weight ( joint probability / proposal )**\n",
    "\n",
    "`P_G(prob_in; 1,1) * P_N(m; 0,2) * P_N(b; 0,2) * ( i=1 to N PI( P_B(o_i) )) *  ( i=1 to N PI( P_N( y_i; m*x_i+b, o_i(prob_out) + (1-o_i)*prob_in))   /  P_G(prob_in; 1,1) * P_N(m; 0,2) * P_N(b; 0,2) * ( i=1 to N PI( P_B(o_i) )`\n",
    "\n",
    "\n",
    "`P_G(prob_in; 1,1) * P_N(m; 0,2) * P_N(b; 0,2) * ( i=1 to N PI( P_B(o_i) )` cancel out\n",
    "\n",
    "and we are left with:\n",
    "\n",
    "`( i=1 to N PI( P_N( y_i; m*x_i+b, o_i(prob_out) + (1-o_i)*prob_in))`\n",
    "\n",
    "\n",
    "**4.Calculate the weight**\n",
    "\n",
    "given the values of the trace above with `ys` constrained\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Distributions.probs in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Gen.Trace, ::String)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Gen.Trace, ::String)",
      ""
     ]
    }
   ],
   "source": [
    "using Distributions\n",
    "xs = [-3.8,3.6,-3.7,0.0,3.5]\n",
    "ys = [3.6, -3.5, -3.6, 0, 3.5]\n",
    "os = [trace[\"o1\"],trace[\"o2\"],trace[\"o3\"],trace[\"o4\"],trace[\"o5\"]]\n",
    "\n",
    "m = trace[\"slope\"]\n",
    "b = trace[\"intercept\"]\n",
    "inlier_noise = trace[\"inlier_noise\"]\n",
    "outlier_noise = 10.\n",
    "\n",
    "sum_prob = 0\n",
    "for i in 1:5\n",
    "    val = logpdf( Normal(m*xs[i]+b,  os[i] ? outlier_noise : inlier_noise), ys[i])\n",
    "    sum_prob += val\n",
    "end\n",
    "    \n",
    "println(\"Likelihood: $sum_prob\")\n",
    "println(\"trace.log_weight: $(trace.log_weight)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: linear_regression_likelihood_weighting not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: linear_regression_likelihood_weighting not defined",
      "",
      " in macro expansion; at ./In[45]:5 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "traces = []\n",
    "for replicate=1:36\n",
    "    trace = Trace()\n",
    "    num_samples = 20000\n",
    "    push!(traces, linear_regression_likelihood_weighting(num_samples, xs_, ys_))\n",
    "end\n",
    "\n",
    "plt[:figure](figsize=(18, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    plt[:subplot](4, 9, i)\n",
    "    ax = plt[:gca]()\n",
    "    xlim = [-4., 4.]\n",
    "    ylim = [-4., 4.]\n",
    "    render_linear_regression_outliers_trace(trace, xs_, ax, xlim, ylim)\n",
    "end\n",
    "plt[:tight_layout]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition linear_regression_outliers(Gen.Trace, Array{Float64, 1}) in module Main at In[29]:2 overwritten at In[46]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "linear_regression_outliers (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear_regression_outliers(T::Trace, xs::Array{Float64,1})\n",
    "    inlier_noise = gamma(1., 1.) ~ \"inlier_noise\"\n",
    "    outlier_noise = 10.0\n",
    "    prob_outlier = 0.1\n",
    "    slope = normal(0.0, 2.0) ~ \"slope\"\n",
    "    intercept = normal(0.0, 2.0) ~ \"intercept\"\n",
    "    ys = Array{Float64, 1}(length(xs))\n",
    "    for i=1:length(xs)\n",
    "        y_mean = intercept + slope * xs[i]\n",
    "        noise = (flip(prob_outlier) ~ \"o$i\") ? outlier_noise : inlier_noise \n",
    "        ys[i] = normal(y_mean, noise) ~ \"y$i\"\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
