{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring the goals of autonomous agents in Gen.jl\n",
    "\n",
    "Gen.jl is a a runtime system and meta-programming library for compositional probabilistic generative models, inference algorithms, and deep learning. This tutorial will show you how to use Gen.jl to build a probabilistic model of an autonomous agent that has latent beliefs and goals, and use probabilistic inference to infer the agent's goals given their observed behavior. This model is based on research at MIT ProbComp ([Cusumano-Towner et al., 2017](https://arxiv.org/abs/1704.04977))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Gen\n",
    "srand(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modeling an autonomous agent\n",
    "\n",
    "In Gen.jl, probabilistic models are represented by probabilistic programs. Probabilistic programs are are programmatic descriptions of stochastic generative processes. A probabilistic program in Gen.jl is very much like a regular Julia function, except that certain expressions in the program are labeled with names using the \"`~`\" symbol, and that the syntax for defining a probabilistic program is slightly different than the syntax for defining a Julia function. \n",
    "\n",
    "Below, we define an `agent_model` probabilistic program that models the beliefs, goals, and goal-directed motion of an autonomous agent. The model assumes the agent starts at a given location in a scene, and desires to move to a goal location. We model the motion of the agent by assuming that the agent walks along a path from the goal to its destination that is constructed using a path-planning algorithm based on the rapidly-exploring random tree (RRT) algorithm from robotics. We have implemented the RRT algorithm and simple library for composing scenes in Julia source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include(\"scene.jl\")\n",
    "include(\"path_planner.jl\")\n",
    "include(\"uniform_2d.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@program agent_model() begin\n",
    "    \n",
    "    # assumed scene\n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    wall_height = 30.\n",
    "    add!(scene, Wall(Point(20., 40.), 1, 40., 2., wall_height))\n",
    "    add!(scene, Wall(Point(60., 40.), 2, 40., 2., wall_height))\n",
    "    add!(scene, Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height))\n",
    "    add!(scene, Wall(Point(20., 80.), 1, 15., 2., wall_height))\n",
    "    add!(scene, Wall(Point(20., 40.), 2, 40., 2., wall_height))    \n",
    "    \n",
    "    # time points at which we observe the agent's location\n",
    "    observation_times = collect(linspace(0.0, 200.0, 20)) ~ \"times\"\n",
    "    \n",
    "    # assumed speed of the agent\n",
    "    speed = 1.0\n",
    "    \n",
    "    # the starting location of the agent is a random point in the scene\n",
    "    start = uniform_2d(0, 100, 0, 100) ~ \"start\"\n",
    "    #start = Point(uniform(0, 100), uniform(0, 100)) ~ \"start\"\n",
    "    \n",
    "    # the destination of the agent is a random point in the scene\n",
    "    destination = uniform_2d(0, 100, 0, 100) ~ \"destination\"\n",
    "    #destination = Point(uniform(0, 100), uniform(0, 100)) ~ \"destination\"\n",
    "    \n",
    "    # the path of the agent from its start location to its destination\n",
    "    # uses a simple 2D holonomic path planner based on RRT (path_planner.jl)\n",
    "    (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    \n",
    "    if isnull(final_path)\n",
    "        \n",
    "        # the agent could not find a path to its destination\n",
    "        # assume it stays at the start location indefinitely\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        \n",
    "        # the agent found a path to its destination\n",
    "        # assume it moves from the start to the destinatoin along the path at constnat speed\n",
    "        # sample its location along this path for each time in observation times\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    \n",
    "    # assume that the observed locations are noisy measurements of the true locations\n",
    "    # assume the noise is normally distributed with standard deviation 'noise'\n",
    "    noise = 1.0\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = normal(locations[i].x, noise) ~ \"x$i\"\n",
    "        measured_y = normal(locations[i].y, noise) ~ \"y$i\"\n",
    "    end\n",
    "    \n",
    "    # record other program state for rendering\n",
    "    scene ~ \"scene\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute this probabilistic program to generate probable scenarios. When we execute a probabilistic program, we record the values of any named expressions that were encountered during its execution (e.g. `~ \"start\"`, `~ \"destination\"`) into a **trace**. We create a new empty trace with `Trace()`, and we execute a probabilistic program and record its expressions into a trace with `@generate(trace, program(args))`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "@generate(trace, agent_model())\n",
    "println(\"start: \", value(trace, \"start\"))\n",
    "println(\"destination: \", value(trace, \"destination\"))\n",
    "println(\"x1 through x4: \", map((i) -> value(trace, \"x$i\"), 1:4))\n",
    "println(\"y1 through y4: \", map((i) -> value(trace, \"y$i\"), 1:4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we execute the program again it again, we get a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "@generate(trace, agent_model())\n",
    "println(\"start: \", value(trace, \"start\"))\n",
    "println(\"destination: \", value(trace, \"destination\"))\n",
    "println(\"x1 through x4: \", map((i) -> value(trace, \"x$i\"), 1:4))\n",
    "println(\"y1 through y4: \", map((i) -> value(trace, \"y$i\"), 1:4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the whole trace. For now, don't worry about constraints, interventions, or proposals. Note that the `recorded` section lists the values that each of the named expressions took during the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizing the probabilistic behavior of a model using a trace rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing a trace is not a very good way to understand the probabilistic behavior of a program. Instead, we use a **trace rendering** to produce a visual representation of the trace. The trace rendering encodes the trace into a representation that the human visual system can quickly interpret. In Gen.jl a trace renderer is simply object that has a method \"`render(renderer, trace::Trace)`\". In Jupyter notebooks, we render traces using JavaScript code that renders traces onto a Document Object Model (DOM) element in the output of notebook cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a trace renderer for `agent_model` using JavaScript and CSS. In particular we use the Javascript data visualization library [D3](https://d3js.org/). First we include some CSS to define visual features of the trace renderings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"<style>\n",
    "    circle { \n",
    "        r: 2\n",
    "    }\n",
    "    .start {\n",
    "        fill: blue;\n",
    "    }\n",
    "    .destination {\n",
    "        fill: red;\n",
    "    }\n",
    "    .path {\n",
    "        fill: orange;\n",
    "        fill-opacity: 0.3;\n",
    "    }\n",
    "    .path_segments {\n",
    "        stroke: black;\n",
    "        stroke-opacity: 0.2;\n",
    "    }\n",
    "    .wall {\n",
    "        fill: gray\n",
    "    }\n",
    "    .tree {\n",
    "        fill: green\n",
    "    }\n",
    "    .score {\n",
    "        text-anchor: middle;\n",
    "        font-size: 10px;\n",
    "    }\n",
    "    .interventions {\n",
    "        stroke: black;\n",
    "        stroke-width: 1;\n",
    "    }\n",
    "    .constraints {\n",
    "        stroke: black;\n",
    "        stroke-width: 1;\n",
    "        stroke-dasharray: 1, 1;\n",
    "    }\n",
    "    .legend {\n",
    "        font-size: 8px;\n",
    "        alignment-baseline: middle;\n",
    "    }\n",
    "</style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the trace renderer in Javascript, and register it with Gen using the Javascript function `Gen.register_jupyter_renderer`. Each Javascript trace renderer is given a name when it is registered, so that the Julia code can send the trace data to the right renderer. A Javascript trace renderer is a function with signature `function(dom_id, trace, configuration) {.. }`. The first argument `dom_id` defines what element of the DOM the renderer should write to, and `trace` contains the trace data sent from Julia. The Javascript code in the cell below should have correct Javascript syntax highlighting (you may have to click in the cell to activate the syntax highlighting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript\"\"\"\n",
    "\n",
    "// Gen.jl provides a Jupyter notebook extension that allows trace to be\n",
    "// passed from Julia to Javscript rendering functions.\n",
    "var Gen = require(\"nbextensions/gen_notebook_extension/main\");\n",
    "\n",
    "// We use D3 for the trace rendering in this example notebook. However,\n",
    "// in principle any Javascript library for graphics or visualization\n",
    "// can be used to render Gen.jl traces.\n",
    "var d3 = require(\"nbextensions/d3/d3.min\");\n",
    "\n",
    "// Add an SVG element representing the scene.\n",
    "function add_svg(parent, trace) {\n",
    "    return parent.append(\"svg\")\n",
    "        .attr(\"viewBox\", \"0 0 100 100\")\n",
    "        .attr(\"position\", \"absolute\")\n",
    "        .style(\"height\", \"100%\");\n",
    "}\n",
    "\n",
    "function add_svg_if_not_exists(parent, trace) {\n",
    "    var svg = parent.selectAll(\"svg\").data([\"\"]);\n",
    "    return svg.enter().append(\"svg\")\n",
    "        .attr(\"viewBox\", \"0 0 100 100\")\n",
    "        .attr(\"position\", \"absolute\")\n",
    "        .style(\"height\", \"100%\")\n",
    "        .merge(svg);\n",
    "}\n",
    "\n",
    "function add_bounding_box(svg) {\n",
    "    svg.selectAll(\"rect\").data([\"\"]).enter().append(\"rect\")\n",
    "        .attr(\"width\", \"100%\")\n",
    "        .attr(\"height\", \"100%\")\n",
    "        .attr(\"stroke\", \"#000\")\n",
    "        .attr(\"fill\", \"#FFF\")\n",
    "        .attr(\"fill-opacity\", 0.0);\n",
    "}\n",
    "\n",
    "// Add the static elements of the scene\n",
    "function add_scene(svg, trace) {\n",
    "    var scene = Gen.find_choice(trace, \"scene\");\n",
    "    \n",
    "    var trace_trees = scene.value.obstacles.filter(function(element) { return element.name == \"Tree\";});\n",
    "    var trees = svg.selectAll(\".tree\").data(trace_trees);\n",
    "    trees.exit().remove();\n",
    "    trees.enter().append(\"rect\").classed(\"tree\", true).classed(\"trace\", true)\n",
    "      .merge(trees)\n",
    "        .attr(\"x\", function(d) { return d.center.x - d.size/2.0; })\n",
    "        .attr(\"y\", function(d) { return d.center.y - d.size/2.0; })\n",
    "        .attr(\"width\", function(d) { return d.size; })\n",
    "        .attr(\"height\", function(d) { return d.size; });\n",
    "    \n",
    "    var trace_walls = scene.value.obstacles.filter(function(element) { return element.name == \"Wall\";});\n",
    "    var walls = svg.selectAll(\".wall\").data(trace_walls);\n",
    "    walls.exit().remove();\n",
    "    walls.enter().append(\"rect\").classed(\"wall\", true).classed(\"trace\", true)\n",
    "      .merge(walls)\n",
    "        .attr(\"x\", function(d) { return d.start.x; })\n",
    "        .attr(\"y\", function(d) { return d.start.y; })\n",
    "        .attr(\"width\", function(d) { return d.orientation == 1 ? d.length : d.thickness; })\n",
    "        .attr(\"height\", function(d) { return d.orientation == 2 ? d.length : d.thickness; });\n",
    "}\n",
    "\n",
    "// Add the starting location of the agent\n",
    "function add_start(svg, trace) {\n",
    "    var trace_start = Gen.find_choice(trace, \"start\");\n",
    "    var start = svg.selectAll(\".start\").data(trace_start ? [trace_start] : []);\n",
    "    start.exit().remove();\n",
    "    start.enter().append(\"circle\").classed(\"start\", true)\n",
    "      .merge(start)\n",
    "        .attr(\"cx\", function(d) { return d.value.x; })\n",
    "        .attr(\"cy\", function(d) { return d.value.y; });\n",
    "}\n",
    "\n",
    "// Add the destination location of the agent\n",
    "function add_destination(svg, trace) {\n",
    "    var trace_dest = Gen.find_choice(trace, \"destination\");\n",
    "    var dest = svg.selectAll(\".destination\").data(trace_dest ? [trace_dest] : []);\n",
    "    dest.exit().remove();\n",
    "    dest.enter().append(\"circle\").classed(\"destination\", true)\n",
    "      .merge(dest)\n",
    "        .attr(\"cx\", function(d) { return d.value.x; })\n",
    "        .attr(\"cy\", function(d) { return d.value.y; });\n",
    "}\n",
    "\n",
    "// Add the path that the agent takes from its start to destination\n",
    "// Show the measured location of the agent along its path at each \n",
    "// of the measured time points.\n",
    "function add_path(svg, trace, update) {\n",
    "    var times = Gen.find_choice(trace, \"times\").value;\n",
    "    var path_point_data = [];\n",
    "    for (var i=1; i<=times.length; i++) {\n",
    "        var x = Gen.find_choice(trace, \"x\" + i);\n",
    "        var y = Gen.find_choice(trace, \"y\" + i);\n",
    "        if (x && y) {\n",
    "            path_point_data.push({x: x, y: y, where: x.where == y.where ? x.where : \"mixed\" });\n",
    "        }\n",
    "    }\n",
    "    var path_segment_data = [];\n",
    "    for (var i=1; i<times.length; i++) {\n",
    "        var x_cur = Gen.find_choice(trace, \"x\" + i);\n",
    "        var y_cur = Gen.find_choice(trace, \"y\" + i);\n",
    "        var x_next = Gen.find_choice(trace, \"x\" + (i+1));\n",
    "        var y_next = Gen.find_choice(trace, \"y\" + (i+1));\n",
    "        if (x_cur && y_cur && x_next && y_next) {\n",
    "            path_segment_data.push({prev: {x: x_cur, y: y_cur},\n",
    "                                    next: {x: x_next, y: y_next}});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    var path_segments = svg.selectAll(\".path_segments\").data(path_segment_data);\n",
    "    path_segments.exit().remove();\n",
    "    path_segments.enter().append(\"line\").classed(\"path_segments\", true).classed(\"trace\", true)\n",
    "        .merge(path_segments)\n",
    "        .attr(\"x1\", function(d) { return d.prev.x.value; })\n",
    "        .attr(\"y1\", function(d) { return d.prev.y.value; })\n",
    "        .attr(\"x2\", function(d) { return d.next.x.value; })\n",
    "        .attr(\"y2\", function(d) { return d.next.y.value; });\n",
    "    \n",
    "    var path_points = svg.selectAll(\".path\").data(path_point_data);\n",
    "    path_points.exit().remove();\n",
    "    path_points.enter().append(\"circle\").classed(\"path\", true).classed(\"trace\", true)\n",
    "        .on(\"mouseover\", handleMouseOver)\n",
    "        .on(\"mouseout\", handleMouseOut)\n",
    "        .merge(path_points)\n",
    "        .attr(\"cx\", function(d) { return d.x.value; })\n",
    "        .attr(\"cy\", function(d) { return d.y.value; });\n",
    "    \n",
    "    function handleMouseOver(d, i) {\n",
    "        var x = d.x.value;\n",
    "        var y = d.y.value;\n",
    "        svg.append(\"text\").attr(\"id\", \"t\" + \"-\" + i).attr(\"x\", x).attr(\"y\", y)\n",
    "            .attr(\"font-size\", \"6px\").attr(\"pointer-events\", \"none\")\n",
    "            .text([x.toFixed(1), y.toFixed(1)]);\n",
    "    };\n",
    "                              \n",
    "    function handleMouseOut(d, i) {\n",
    "        var x = d.x.value;\n",
    "        var y = d.y.value;\n",
    "        d3.select(\"#t\" + \"-\" + i).remove();\n",
    "    };\n",
    "}\n",
    "\n",
    "// Set a different style to elements if they were intervened in the trace\n",
    "// with intervene! or constrained with constrain!\n",
    "function apply_styles(svg) {\n",
    "    svg.selectAll(\".trace\")\n",
    "        .classed(\"interventions\", function(d) { return d.where == Gen.interventions; })\n",
    "        .classed(\"constraints\", function(d) { return d.where == Gen.constraints; });\n",
    "}\n",
    "\n",
    "// Add the score of the trace to the bottom of the scene\n",
    "function add_score(svg, trace) {\n",
    "    var score = svg.selectAll(\".score\").data([\"\"]);\n",
    "    score.enter().append(\"text\").classed(\"score\", true)\n",
    "        .attr(\"x\", 50).attr(\"y\", 95)\n",
    "        .text(trace.log_weight.toFixed(2));\n",
    "}\n",
    "\n",
    "// The main Javascript trace rendering function, registered with Gen\n",
    "// Renders 'trace' onto the the DOM element #'id'\n",
    "Gen.register_jupyter_renderer(\"agent_model_renderer\", function(id, trace, conf) {\n",
    "    var root = d3.select(\"#\" + id);\n",
    "    var svg;\n",
    "    switch (conf.mode) {\n",
    "        case \"overlay\":\n",
    "            root = add_svg_if_not_exists(root, trace);\n",
    "            svg = add_svg(root, trace);\n",
    "            break;\n",
    "        case \"overwrite\":\n",
    "            svg = add_svg_if_not_exists(root, trace);\n",
    "            break;\n",
    "        default:\n",
    "            break;\n",
    "    }\n",
    "    add_bounding_box(svg);\n",
    "    if (conf.show_path) {\n",
    "        add_path(svg, trace, false);\n",
    "    }\n",
    "    add_start(svg, trace);\n",
    "    add_destination(svg, trace);\n",
    "    apply_styles(svg);\n",
    "    add_scene(svg, trace);\n",
    "    if (conf.show_score) {\n",
    "        add_score(svg, trace);\n",
    "    }\n",
    "});\n",
    "\n",
    "// An secondary trace rendering that just draws a legend onto the DOM element #'id'\n",
    "Gen.register_jupyter_renderer(\"agent_model_legend_renderer\", function(id, trace, conf) {\n",
    "    var root = d3.select(\"#\" + id);\n",
    "    root.append(\"circle\").classed(\"start\", true).attr(\"cx\", 10).attr(\"cy\", 10);\n",
    "    root.append(\"text\").text(\"Starting location\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 10);\n",
    "    root.append(\"circle\").classed(\"destination\", true).attr(\"cx\", 10).attr(\"cy\", 20);\n",
    "    root.append(\"text\").text(\"Destination\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 20);\n",
    "    root.append(\"circle\").classed(\"path\", true).attr(\"cx\", 10).attr(\"cy\", 30);\n",
    "    root.append(\"text\").text(\"Location on path\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 30);\n",
    "    \n",
    "    root.append(\"rect\").classed(\"tree\", true).attr(\"x\", 5).attr(\"y\", 35).attr(\"width\", 10).attr(\"height\", 10);\n",
    "    root.append(\"text\").text(\"Tree\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 40);\n",
    "    root.append(\"rect\").classed(\"wall\", true).attr(\"x\", 5).attr(\"y\", 50).attr(\"width\", 10).attr(\"height\", 2);\n",
    "    root.append(\"text\").text(\"Wall\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 50);\n",
    "    \n",
    "    root.append(\"circle\").classed(\"interventions\", true).attr(\"cx\", 10).attr(\"cy\", 60).style(\"fill\", \"white\");\n",
    "    root.append(\"text\").text(\"Intervened\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 60);\n",
    "    root.append(\"circle\").classed(\"constraints\", true).attr(\"cx\", 10).attr(\"cy\", 70).style(\"fill\", \"white\");\n",
    "    root.append(\"text\").text(\"Constrained\").classed(\"legend\", true).attr(\"x\", 20).attr(\"y\", 70);\n",
    "});\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a DOM element that the trace renderer renders to using the `Figure` function in Julia. The `here(figure)` places a DOM element in the output of the cell onto which Javascript trace renderers will be able to render traces. It should appear as as a mostly empty output area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct a Julia trace renderer object that will delegate rendering to the Javascript trace renderer that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overwrite\", \"show_path\" => true));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then execute the program, and render the resulting trace. You should see the trace rendering appear on the left side of the rendering area above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "@generate(trace, agent_model())\n",
    "attach(renderer, figure => 1)\n",
    "render(renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a renderer that just shows the legend. We ask that renderer to put a legend in the right side of the rendering area above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "legend_renderer = JupyterInlineRenderer(\"agent_model_legend_renderer\", Dict())\n",
    "attach(legend_renderer, figure => 2)\n",
    "render(legend_renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilistic program is stochastic, and the distribution over its executions defines a probability distribution over potential scenarios. Let's get a sense of this probability distribution by rendering many executions, one after another, in an animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(legend_renderer, figure => 2)\n",
    "render(legend_renderer, trace)\n",
    "attach(renderer, figure)\n",
    "for i=1:100\n",
    "    trace = Trace()\n",
    "    @generate(trace, agent_model())\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render many runs side by side in a grid, instead of an animation. This also gives a sense of the probability distribution represented by the probabilistic program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = Trace()\n",
    "    @generate(trace, agent_model())\n",
    "    attach(renderer, (figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of Gen.jl is the ability to constrain the values of random choices that a probabilistic program makes during the course of its execution. Let's see how we can modify the behavior of the program if we constrain the starting location of the agent and its destination location using the `constrain!(trace, name, value)` method. We will constrain the start location to lie in the upper left corner and the destination to lie in the bottom right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=2, num_cols=6, width=900, height=300, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i=1:12\n",
    "    trace = Trace()\n",
    "    constrain!(trace, \"start\", Point(10, 10))\n",
    "    constrain!(trace, \"destination\", Point(90, 90))\n",
    "    @generate(trace, agent_model())\n",
    "    attach(renderer, (figure => i))\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a sense of the variability in the paths that the agent takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a sense for the variability by overlaying many traces on top of one another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20,\n",
    "                titles=[\"Trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(legend_renderer, figure => 2)\n",
    "render(legend_renderer, trace)\n",
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overlay\", \"show_path\" => true))\n",
    "attach(renderer, figure)\n",
    "for i=1:20\n",
    "    trace = Trace()\n",
    "    intervene!(trace, \"start\", Point(10, 10))\n",
    "    intervene!(trace, \"destination\", Point(90, 90))\n",
    "    @generate(trace, agent_model())\n",
    "    render(renderer, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Probabilistic inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have generated scenarios that the model thinks are probable, and we have constrained some random choices and simulated the consequence. However, suppose we had observed the start location of the agent, and a certain sequence of locations of the agent along its path, and we wanted to know probable goal locations?\n",
    "\n",
    "This is a query that cannot be answered simply by forward simulation of the program, because the location of the agent is a *consequence* and not a *cause* of the destination. We can easily find probable consequences given the causes as we did above, but finding probable causes given the consequences requires a bit more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example dataset showing measured locations for the first 7 time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    Point(10.3867,10.3889)\n",
    "    Point(11.0188,20.0843)\n",
    "    Point(11.6663,30.0142)\n",
    "    Point(11.4507,41.5159)\n",
    "    Point(13.8081,53.0258)\n",
    "    Point(13.1958,61.3572)\n",
    "    Point(17.1566,73.7131)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in inference is to constrain the random choices that are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "constrain!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we run the program in this trace, we find that the score of the trace tells us how well the other values in the trace match the value of the constraints. Very negative scores that the other values in the trace, such as the destination and the projected path, do not match well with the constrained path points. The path points that were constrained are identified in the trace renderings by a dashed border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=3, num_cols=3, width=900, height=900, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overlay\",\n",
    "                                                              \"show_path\" => true,\n",
    "                                                              \"show_score\" => true))\n",
    "for i=1:30\n",
    "    t = deepcopy(trace)\n",
    "    @generate(t, agent_model())\n",
    "    attach(renderer, (figure => i))\n",
    "    render(renderer, t)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a large number of traces generated by the program, and a score for each trace that tells us how well that trace matches the constraints, we can select those trace that match the constraints. These traces then represent plausible hypotheses that can explain the observed data. This is the approach taken by the two basic inference algorithms that we implement next, *Importance Sampling* and *Metropolis-Hastings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below shows a basic importance sampling procedure that uses the score of traces to probabilistically filter them and tries to select a trace that explains the data well. Note that this procedure is a regular Julia function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function agent_model_importance_sampling(trace::Trace, num_samples::Int)\n",
    "    \n",
    "    # the 'trace' argument contains the constraints that represent the \n",
    "    # observed dataset. \n",
    "    \n",
    "    # perform many independent executions of the probabilistic program, and \n",
    "    # record each execution in a trace. store the 'score' for each trace, \n",
    "    # which encodes how well the trace matches the constraints\n",
    "    traces = Vector{Trace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        @generate(t, agent_model())\n",
    "        scores[k] = score(t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    \n",
    "    # compute a reltaive weight for each trace indicating how well the trace\n",
    "    # matches the constraints relative to the other traces generated. A large\n",
    "    # weight indicates that the trace matches the constraints well, and may be\n",
    "    # a better explanation for the observed data than other trace.\n",
    "    \n",
    "    # weights = exp(scores) / sum(exp(scores))\n",
    "    weights = exp(scores - logsumexp(scores))\n",
    "    weights = weights / sum(weights)\n",
    "    \n",
    "    # pick a trace in propotion to its relative weight and return it\n",
    "    chosen = rand(Categorical(weights))\n",
    "    return traces[chosen]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this Julia function treats the execution traces of the probabilistic program `agent_model` as data, this inference procedure is an example of a [meta-program](https://en.wikipedia.org/wiki/Metaprogramming). In Gen.jl, inference is done using meta-programs that reason about the traces of other programs. This is in contrast to most other probabilistic programming systems, in which users do not write their own custom meta-programs, but instead rely on built-in generic inference techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the output of our importance sampling procedure. Recall that each run of the procedure produces one trace of the `agent_model` probabilistic program. Note that the importance sampling procedure is stochastic---repeated executions will generate different traces. This is an important feature---we want inference algorithms to give us probable explanations for the data, but also a sense of how uncertain we are in those explanations. By executing the inference algorithm many times, we can get a sense of the uncertainty in the inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overlay\", \"show_path\" => true,\n",
    "                                                              \"show_score\" => false))\n",
    "num_approximate_samples = 30\n",
    "trace = Trace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, (figure => i))\n",
    "    title =  \"SIR ($num_samples particles)\"\n",
    "    for j=1:num_approximate_samples\n",
    "        output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the inference algorithm using `num_samples=1`, `num_samples=4`, and `num_samples=16`. Note that when we increase `num_samples` we get more plausible traces as output. For `num_samples=16`, the algorithm tells us that it thinks the agent is headed either into the box or in the bottom left or bottom of the scene. Also note that the more plausible answers come at a greater computation cost---we have to wait longer for each new sample to arrive. Understanding the time-accuracy tradeoffs in approximate probabilistic inference algorithms is an active area of research (see [Cusumano-Towner, Mansinghka 2016](https://arxiv.org/abs/1705.07224) for recent work in this area)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we show a basic Metropolis-Hastings inference allgorithm written in Gen.jl that operates according to similar principles. Instead of generating a bunch of traces and then scoring each and selecting it as output, Metropolis-Hastings generates traces one by one and decides to stochastically replace the previous trace with a new trace if the new trace has a higher score than the previous trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overwrite\",\n",
    "                                                              \"show_path\" => true,\n",
    "                                                              \"show_score\" => true))\n",
    "figure = Figure(num_rows=1, num_cols=3, width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=[\"proposed trace\", \"current trace\"])\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(legend_renderer, figure => 3)\n",
    "render(legend_renderer, trace)\n",
    "current_trace = Trace()\n",
    "intervene!(current_trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(dataset)\n",
    "    constrain!(current_trace, \"x$i\", point.x)\n",
    "    constrain!(current_trace, \"y$i\", point.y)\n",
    "end\n",
    "@generate(current_trace, agent_model())\n",
    "current_score = score(current_trace)\n",
    "for i=1:100\n",
    "    proposed_trace = deepcopy(current_trace)\n",
    "    @generate(proposed_trace, agent_model())\n",
    "    proposed_score = score(proposed_trace)\n",
    "    if log(rand()) < proposed_score - current_score\n",
    "        current_trace = proposed_trace\n",
    "        current_score = proposed_score\n",
    "    end\n",
    "    attach(renderer, figure => 1)\n",
    "    render(renderer, proposed_trace)\n",
    "    attach(renderer, figure => 2)\n",
    "    render(renderer, current_trace)\n",
    "    sleep(0.1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Improving the model\n",
    "\n",
    "The probabilistic model `agent_model` used above made a lot of assumptions that are unlikely to hold in the real world. For example, the agent always takes pretty direct paths from its starting location to its final destination. What if the agent is more unpredictable? What if it takes detours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a dataset that has a detour in it, and that does not match our model's expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detour_dataset = [\n",
    "    Point(9.59825,8.92063)\n",
    "    Point(21.8936,9.54817)\n",
    "    Point(30.9534,10.8819)\n",
    "    Point(43.1137,9.75395)\n",
    "    Point(48.8929,10.4189)\n",
    "    Point(46.0282,21.7662)\n",
    "    Point(35.0281,25.9994)\n",
    "    Point(27.2084,33.5729)\n",
    "    Point(20.1662,39.9398)\n",
    "    Point(18.7309,50.0026)\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_cols=2, width=900, height=400, trace_width=100, trace_height=100, margin_top=20)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overwrite\",\n",
    "                                                              \"show_path\" => true,\n",
    "                                                              \"show_score\" => false))\n",
    "attach(renderer, figure => 1)\n",
    "\n",
    "# show the dataset above.\n",
    "trace = Trace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "@generate(trace, agent_model())\n",
    "\n",
    "# just show the observed data (don't show the predictions for the remainder of the path)\n",
    "# remove these from the trace to prevent them from being rendered\n",
    "delete!(trace, \"destination\")\n",
    "for i=length(detour_dataset)+1:20\n",
    "    delete!(trace, \"x$i\")\n",
    "    delete!(trace, \"y$i\")\n",
    "end\n",
    "render(renderer, trace)\n",
    "\n",
    "# show a legend\n",
    "attach(legend_renderer, figure => 2)\n",
    "render(legend_renderer, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try to do probabilistic inference given this dataset, using the `agent_model` model. We will use the same importance sampling algorithm we wrote above, with the same settings for the  `num_samples` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "intervene!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overlay\",\n",
    "                                                              \"show_path\" => true,\n",
    "                                                              \"show_score\" => false))\n",
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, figure => i)\n",
    "    for j=1:num_approximate_samples\n",
    "        output_trace = agent_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferences do not look intuitive. This is because the model `agent_model` cannot explain the detour. It assumes that the detour must be the goal, an it explains the observed data as a very unlikely accident of noise. This is an example of **model mis-specification**.  In order to make reasonablee inferences for datasets that may contain a detour, we need to improve our model. Here is a new probabilistic program that models an agent that may or may not use an arbitrary waypoint (e.g. detour) when planning its path from its starting location to its destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere @program agent_waypoint_model() begin\n",
    "    \n",
    "    # assumed scene\n",
    "    scene = Scene(0, 100, 0, 100) # the scene spans the square [0, 100] x [0, 100]\n",
    "    add!(scene, Tree(Point(30, 20))) # place a tree at x=30, y=20\n",
    "    add!(scene, Tree(Point(83, 80)))\n",
    "    add!(scene, Tree(Point(80, 40)))\n",
    "    wall_height = 30.\n",
    "    add!(scene, Wall(Point(20., 40.), 1, 40., 2., wall_height))\n",
    "    add!(scene, Wall(Point(60., 40.), 2, 40., 2., wall_height))\n",
    "    add!(scene, Wall(Point(60.-15., 80.), 1, 15. + 2., 2., wall_height))\n",
    "    add!(scene, Wall(Point(20., 80.), 1, 15., 2., wall_height))\n",
    "    add!(scene, Wall(Point(20., 40.), 2, 40., 2., wall_height))    \n",
    "    \n",
    "    # time points at which we observe the agent's location\n",
    "    observation_times = collect(linspace(0.0, 200.0, 20)) ~ \"times\"\n",
    "    \n",
    "    # assumed speed of the agent\n",
    "    speed = 1.0\n",
    "    \n",
    "    # the starting location of the agent is a random point in the scene\n",
    "    start = uniform_2d(0, 100, 0, 100) ~ \"start\"\n",
    "    \n",
    "    # the destination of the agent is a random point in the scene\n",
    "    destination = uniform_2d(0, 100, 0, 100) ~ \"destination\"\n",
    "    \n",
    "    if (flip(0.5) ~ \"use-waypoint\")\n",
    "        waypoint = uniform_2d(0, 100, 0, 100) ~ \"waypoint\"\n",
    "        (tree1, rough_path1, final_path1) = plan_path(start, waypoint, scene)\n",
    "        (tree2, rough_path2, final_path2) = plan_path(waypoint, destination, scene)\n",
    "        \n",
    "        # if either path planner sub-problem failed, then no path was found (final_path is null)\n",
    "        if isnull(final_path1) || isnull(final_path2)\n",
    "            final_path = Nullable{Path}() # null\n",
    "        else\n",
    "            final_path = Nullable{Path}(concatenate(get(final_path1), get(final_path2)))\n",
    "        end\n",
    "    else\n",
    "        (tree, rough_path, final_path) = plan_path(start, destination, scene)\n",
    "    end\n",
    "    \n",
    "    # the path of the agent from its start location to its destination\n",
    "    # uses a simple 2D holonomic path planner based on RRT (path_planner.jl)\n",
    "    \n",
    "    if isnull(final_path)\n",
    "        \n",
    "        # the agent could not find a path to its destination\n",
    "        # assume it stays at the start location indefinitely\n",
    "        locations = [start for _ in observation_times]\n",
    "    else\n",
    "        \n",
    "        # the agent found a path to its destination\n",
    "        # assume it moves from the start to the destinatoin along the path at constnat speed\n",
    "        # sample its location along this path for each time in observation times\n",
    "        locations = walk_path(get(final_path), speed, observation_times)\n",
    "    end\n",
    "    \n",
    "    # assume that the observed locations are noisy measurements of the true locations\n",
    "    # assume the noise is normally distributed with standard deviation 'noise'\n",
    "    noise = 1.0\n",
    "    for (i, t) in enumerate(observation_times)\n",
    "        measured_x = normal(locations[i].x, noise) ~ \"x$i\"\n",
    "        measured_y = normal(locations[i].y, noise) ~ \"y$i\"\n",
    "    end\n",
    "    \n",
    "    # record other program state for rendering\n",
    "    scene ~ \"scene\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simulations from the program, for a constrained start and destination that both lie one side of the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(num_rows=3, num_cols=6, width=900, height=450, trace_width=100, trace_height=100)\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overwrite\", \"show_path\" => true))\n",
    "traces = []\n",
    "for i=1:18\n",
    "    trace = Trace()\n",
    "    constrain!(trace, \"start\", Point(10, 10))\n",
    "    constrain!(trace, \"destination\", Point(30, 90))\n",
    "    @generate(trace, agent_waypoint_model())\n",
    "    attach(renderer, figure => i)\n",
    "    render(renderer, trace)\n",
    "    push!(traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sometimes, the path has a clear waypoint/detour whereas other times it does not. Run the above cell a few times if you don't initially see a clear waypoint. The current trace rendering does not show the waypoint explicitly, but it could be extended to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do inference in this new model on the detour dataset. We'll use importance sampling again. The only change in this procedure from the earlier importance sampling procedure is the choice of model (`agent_waypoint_model` instead of `agent_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function agent_waypoint_model_importance_sampling(trace::Trace, num_samples::Int)\n",
    "    traces = Vector{Trace}(num_samples)\n",
    "    scores = Vector{Float64}(num_samples)\n",
    "    for k=1:num_samples\n",
    "        t = deepcopy(trace)\n",
    "        @generate(t, agent_waypoint_model())\n",
    "        scores[k] = score(t)\n",
    "        traces[k] = t\n",
    "    end\n",
    "    weights = exp(scores - logsumexp(scores))\n",
    "    weights = weights / sum(weights)\n",
    "    chosen = rand(Categorical(weights))\n",
    "    return traces[chosen]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_list = [1, 4, 16]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n) -> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = Trace()\n",
    "constrain!(trace, \"start\", Point(10, 10))\n",
    "for (i, point) in enumerate(detour_dataset)\n",
    "    constrain!(trace, \"x$i\", point.x)\n",
    "    constrain!(trace, \"y$i\", point.y)\n",
    "end\n",
    "renderer = JupyterInlineRenderer(\"agent_model_renderer\", Dict(\"mode\" => \"overlay\", \"show_path\" => true, \"show_score\" => false))\n",
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, figure => i)\n",
    "    for j=1:num_approximate_samples\n",
    "        output_trace = agent_waypoint_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_trace)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the results are not accurate. Let's try more computation. This may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_list = [64, 256, 1024]\n",
    "figure = Figure(num_rows=1, num_cols=length(num_samples_list),\n",
    "                width=900, height=300, trace_width=100, trace_height=100,\n",
    "                margin_top=20, titles=map((n)-> \"SIR ($n samples)\", num_samples_list))\n",
    "here(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_approximate_samples = 50\n",
    "for (i, num_samples) in enumerate(num_samples_list)\n",
    "    attach(renderer, figure => i)\n",
    "    for j=1:num_approximate_samples\n",
    "        output_sample = agent_waypoint_model_importance_sampling(trace, num_samples)\n",
    "        render(renderer, output_sample)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra computation seems to have given us reasonable inferences. Recall that inference in the original model with a typical dataset only required 16 particles to give reasonalbe results for a particular dataset. Why do we need to do more computation to get accurate inferences for `agent_waypoint_path` than we needed for `agent_model`? This is because a random execution of the improved model is a lot less likely to match a typical dataset generated from it than a random execution of the original model was to match a typical dataset generated from it. Conceptually, the distribution on datasets produced by `agent_waypoint_path` has more entropy than the distribution on datasets produced by `agent_path`. This means we need to increase the number of samples to incrase the probability that we get one that matches the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
